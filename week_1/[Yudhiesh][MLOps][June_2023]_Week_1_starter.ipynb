{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCJ3pvJKY_xV"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "### Problem\n",
        "\n",
        "In the project this week, we will build a machine learning text classifier to predict news categories from the news article text. \n",
        "\n",
        "1. We will iterate on classification models with increasing level of complexity and improved performance: N-gram models, pre-trained Transformer models, and third-party hosted Large Language Models (LLMs).\n",
        "\n",
        "2. We will look at the impact of labeled dataset size and composition on model performance. The labeled dataset will be used for training in case of N-gram models and pre-trained Transformers, and for selecting examples for in-context few-shot learning for LLMs.\n",
        "\n",
        "3. [advanced] As an extension, we will explore how to augment data efficiently to your existing training data (efficiency measured as improvement in performance normalized by volume of data augmented). \n",
        "\n",
        "Throughout the project there are suggested model architectures that we expect to work reasonably well for this problem. But if you wish to extend/modify any part of this pipeline, or explore new model architectures you should definitely feel free to do so.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FNP8FSfZIed"
      },
      "source": [
        "## Step1: Prereqs & Installation\n",
        "\n",
        "Download & Import all the necessary libraries we need throughout the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1LsWxD0ZF3b",
        "outputId": "6df2fbad-0c83-48b1-85af-de014007156b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.30.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.195)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.8)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: asyncio in /usr/local/lib/python3.10/dist-packages (3.4.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.5.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install all the required dependencies for the project\n",
        "\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install sentence-transformers\n",
        "!pip install matplotlib\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install asyncio\n",
        "!pip install nest_asyncio\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yiDpaCRTZOKL"
      },
      "outputs": [],
      "source": [
        "# Package imports that will be needed for this project\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from pprint import pprint\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import nest_asyncio\n",
        "\n",
        "# Needed to run asyncio code in notebook easily\n",
        "# Refer to https://stackoverflow.com/questions/55409641/asyncio-run-cannot-be-called-from-a-running-event-loop-when-using-jupyter-no\n",
        "nest_asyncio.apply()\n",
        "# [TO BE IMPLEMENTED] \n",
        "# Add any other imports needed below depending on the model architectures you are using. For e.g.\n",
        "# from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p9asDVPMZlf3"
      },
      "outputs": [],
      "source": [
        "# Global Constants\n",
        "LABEL_SET = [\n",
        "    'Business',\n",
        "    'Sci/Tech',\n",
        "    'Software and Developement',\n",
        "    'Entertainment',\n",
        "    'Sports',\n",
        "    'Health',\n",
        "    'Toons',\n",
        "    'Music Feeds'\n",
        "]\n",
        "\n",
        "WORD_VECTOR_MODEL = 'glove-wiki-gigaword-100'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-mpnet-base-v2'\n",
        "\n",
        "TRAIN_SIZE_EVALS = [500, 1000, 2000, 5000, 10000, 25000]\n",
        "EPS = 0.001\n",
        "SEED = 0\n",
        "\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLu2IBiqZsgs"
      },
      "source": [
        "## Step 2: Download & Load Datasets \n",
        "\n",
        "[AG News](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) is a collection of more than 1 million news articles gathered from more than 2000 news sources by an academic news search engine. The news topic classification dataset & benchmark was first used in [Character-level Convolutional Networks for Text Classification (NIPS 2015)](https://arxiv.org/abs/1509.01626). The dataset has the text description (summary) of the news article along with some metadata. **For this project, we will use a slightly modified (cleaned up) version of this dataset** \n",
        "\n",
        "Schema:\n",
        "* Source - News publication source\n",
        "* URL - URL of the news article\n",
        "* Title - Title of the news article\n",
        "* Description - Summary description of the news article\n",
        "* Category (Label) - News category\n",
        "\n",
        "Sample row in this dataset:\n",
        "```\n",
        "{\n",
        "    'description': 'A capsule carrying solar material from the Genesis space '\n",
        "                'probe has made a crash landing at a US Air Force training '\n",
        "                'facility in the US state of Utah.',\n",
        "    'id': 86273,\n",
        "    'label': 'Entertainment',\n",
        "    'source': 'Voice of America',\n",
        "    'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n",
        "    'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'\n",
        " }\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jFGaBYdSZtqM"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "DIRECTORY_NAME = \"data\"\n",
        "DOWNLOAD_URL = 'https://corise-mlops.s3.us-west-2.amazonaws.com/project1/agnews.zip'\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"\n",
        "    Download the dataset. The zip contains three files: train.json, test.json and unlabeled.json \n",
        "    \"\"\"\n",
        "    http_response = urlopen(DOWNLOAD_URL)\n",
        "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "    zipfile.extractall(path=DIRECTORY_NAME)\n",
        "\n",
        "# Expensive operation so we should just do this once\n",
        "download_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYnT4BIcZ5vX",
        "outputId": "f3277dd0-f3da-4c0a-ece3-3490f0183d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Dataset train with 25000 rows\n",
            "Loaded Dataset test with 5000 rows\n",
            "Loaded Dataset augment with 150000 rows\n",
            "Loaded Dataset test_mini with 1000 rows\n",
            "\n",
            "Example train row:\n",
            "\n",
            "{'description': 'A capsule carrying solar material from the Genesis space '\n",
            "                'probe has made a crash landing at a US Air Force training '\n",
            "                'facility in the US state of Utah.',\n",
            " 'id': 86273,\n",
            " 'label': 'Entertainment',\n",
            " 'source': 'Voice of America',\n",
            " 'title': 'Capsule from Genesis Space Probe Crashes in Utah Desert',\n",
            " 'url': 'http://www.sciencedaily.com/releases/2004/09/040908090621.htm'}\n",
            "\n",
            "Example test row:\n",
            "\n",
            "{'description': 'European Union regulators will decide Tuesday whether Oracle '\n",
            "                \"Corp.'s hostile \\\\$7.7 billion bid for rival business \"\n",
            "                \"software concern PeopleSoft Inc. can proceed, the EU's \"\n",
            "                'antitrust chief said Friday.',\n",
            " 'id': 278781,\n",
            " 'label': 'Sci/Tech',\n",
            " 'source': 'Washington Post Tech',\n",
            " 'title': \"EU to Rule Tuesday on Oracle's Bid for PeopleSoft\",\n",
            " 'url': 'http://www.washingtonpost.com/wp-dyn/articles/A53747-2004Oct22.html?nav=rss_technology'}\n"
          ]
        }
      ],
      "source": [
        "Datasets = {}\n",
        "\n",
        "for ds in ['train', 'test', 'augment', 'test_mini']:\n",
        "    with open('data/{}.json'.format(ds), 'r') as f:\n",
        "      Datasets[ds] = json.load(f)\n",
        "    print(\"Loaded Dataset {0} with {1} rows\".format(ds, len(Datasets[ds])))\n",
        "\n",
        "print(\"\\nExample train row:\\n\")\n",
        "pprint(Datasets['train'][0])\n",
        "\n",
        "print(\"\\nExample test row:\\n\")\n",
        "pprint(Datasets['test'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TcwebhuYZ8Kb"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = [], []\n",
        "X_test, Y_true = [], []\n",
        "X_augment, Y_augment = [], []\n",
        "\n",
        "for row in Datasets['train']:\n",
        "    X_train.append(row['description'])\n",
        "    Y_train.append(row['label'])\n",
        "\n",
        "for row in Datasets['test_mini']:\n",
        "    X_test.append(row['description'])\n",
        "    Y_true.append(row['label'])\n",
        "\n",
        "for row in Datasets['augment']:\n",
        "    X_augment.append(row['description'])\n",
        "    Y_augment.append(row['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pV9avhWMl5g",
        "outputId": "86ffd273-5821-4a2a-d1ae-c72c58c0cad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unique labels for this dataset are {'Music Feeds', 'Sci/Tech', 'Entertainment', 'Toons', 'Business', 'Software and Developement', 'Sports', 'Health'}\n"
          ]
        }
      ],
      "source": [
        "target_labels = set(Y_true)\n",
        "print(f\"The unique labels for this dataset are {target_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoayaMr8aBwp"
      },
      "source": [
        "## Step 3: [Modeling part 1] N-gram model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2zIahH6aHJ9",
        "outputId": "b5e4bf90-5076-4011-aef0-af7228e0938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating for training data size = 500\n",
            "Accuracy on test set: 0.303\n",
            "Evaluating for training data size = 1000\n",
            "Accuracy on test set: 0.216\n",
            "Evaluating for training data size = 2000\n",
            "Accuracy on test set: 0.329\n",
            "Evaluating for training data size = 5000\n",
            "Accuracy on test set: 0.352\n",
            "Evaluating for training data size = 10000\n",
            "Accuracy on test set: 0.281\n",
            "Evaluating for training data size = 25000\n",
            "Accuracy on test set: 0.368\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "N_GRAM_SIZE = 5\n",
        "LR_MAX_ITER = 1_000\n",
        "\n",
        "models = {}\n",
        "\n",
        "for n in TRAIN_SIZE_EVALS:\n",
        "    print(\"Evaluating for training data size = {}\".format(n))\n",
        "    X_train_i = X_train[:n]\n",
        "    Y_train_i = Y_train[:n]\n",
        "\n",
        "    \"\"\"\n",
        "    [TO BE IMPLEMENTED]\n",
        "        \n",
        "    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "    You have to replace it with a pipeline object which contains at least two steps:\n",
        "    (1) mapping the input document to an N-gram feature extractor. You can use feature extractors\n",
        "        provided by sklearn out of the box (e.g. CountVectorizer, TfidfTransformer)\n",
        "    (2) a classifier that predicts the class label using the feature output of first step\n",
        "\n",
        "    You can add other steps to preproces, post-process your data as you see fit. \n",
        "    You can also try any sklearn model architecture you want, but a linear classifier\n",
        "    will do just fine to start with\n",
        "\n",
        "    e.g. \n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', <your WordVectorFeaturizer class instance here>),\n",
        "        ('classifier', <your sklearn classifier class instance here>)\n",
        "    ])\n",
        "\n",
        "    Reference: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "    \"\"\"\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            ('featurizer', CountVectorizer(ngram_range=(N_GRAM_SIZE, N_GRAM_SIZE))),\n",
        "            ('classifier', LogisticRegression(max_iter=LR_MAX_ITER))\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # train\n",
        "    pipeline.fit(X_train_i, Y_train_i)\n",
        "    # predict\n",
        "    Y_pred_i = pipeline.predict(X_test)\n",
        "    # record results\n",
        "    models[n] = {\n",
        "        'pipeline': pipeline,\n",
        "        'test_predictions': Y_pred_i,\n",
        "        'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "    }\n",
        "    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBxVNbWBaMhc"
      },
      "source": [
        "## Step 4: [Modeling part 2] Pretrained Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce6b242414a543c2a12ed96d0b172e6d",
            "91317d2d089f4dfe853c38cd730b7fab",
            "27d32f550564433eaba12c93169857fc",
            "9a7279d57acf492584ecf083bb29e343",
            "aa962c230f9442168ff130d8c24965df",
            "ede7440670e84051898ad7de850dc51a",
            "2a8eb5097af34051b00b1b73a1ebabda",
            "11b31dfb9710470d925bc5a4d28749f3",
            "9fe92088226c4e7d85fd6ec9d0ca328b",
            "7ca04b44470745a3b257c36a5c128f25",
            "94514a4f0735411d8c0c315d082dab8c",
            "d90731d190b146b29cf1cc0ce7371f76",
            "4a412a0902f44c47a5722077b1ae3cea",
            "47f5e52078d4420db01dc8cb7cafae8a",
            "258b6ddc2b9a49988586f8ee285fd582",
            "2f0d937f49b74557ab62a59696678273",
            "54a3d9df550e476f8e7b8126a1754023",
            "1a16643528c0498d87bd99cb439d0f3d",
            "cb14e86eda594f498ecfa3ac4426a829",
            "dcbf588918514566852ba12725188f3e",
            "34aa730a9f9f480390d84fe8cb314423",
            "af41c783e07643218341143e44b34945",
            "d8c4b5d46b534647b56e28be51c71143",
            "f85fdbc2948c40b8922da88e56048018",
            "b6702432569e462b80b65652a1bef61d",
            "1a3de692fe6b4334a54177d09f0b1537",
            "adcc4450f2774f12a972ae6730d51f2f",
            "c3beb5860a31413b8e7f98c2ec5d51ab",
            "011bf0714df9442db9081a6c0057b489",
            "b344f30766694376b26811f8996e08e3",
            "19e57fbcf2dd45a5b457665422592b37",
            "d8260a40e68442ff81d0b447628f6e82",
            "7e1ca31766d74fb39e52651b4f912e5d",
            "a72c1a13a5ad428188e3152be9096148",
            "5ed61b77e193438593a8669fb67db110",
            "b2a716de3b434eb8b9a4e1b479347bc7",
            "c20ac4536338433395437677287afff7",
            "a560f5f8fe2d4d5e8e742f63f24c8d65",
            "174bcbf0f3d7426883721f66d8b89dd3",
            "458edd02de9d47f8b437707e25599d39",
            "11617e6c55ec41fbb4ce751e7321dc6d",
            "22be8668de104753996c2def67c461f9",
            "869a56e33c1b4497a994cdd237ee8182",
            "4287e71ffa84420ebd455d6fa8911d6d",
            "acb46db6a67a4ff1a9c76dff39cd96b9",
            "72f4d0ef082146a9918e39fa17161357",
            "428489140653408fad835d49db6351ea",
            "7103b66eec084c6d99cd860820332555",
            "78a7c67427204cab8157bd5ef7f86011",
            "33cce55cfdf44bd7bce072e3959eea2e",
            "8f9fe7dc8fdb45d3bac2d11f8b83aa15",
            "3158a21871e549baac7e2238a4f70c6f",
            "ce8107b5f1744244a71a039f7b722d7d",
            "079ab707a9644a46a921128f52975e7f",
            "744fda458d6f410b96c2a863276dac3c",
            "812e1f6d4aa849e49df5a04e9786720e",
            "5ce06b37eb7e4a3981de3aa5711e3e4b",
            "4a36e669e0434b1a8099ee71b3414361",
            "2bffc337134f438c91e49d8b0ed07d30",
            "bae40bf6eb74481485c3277004e292c0",
            "24077d10323e4cf6afde6bda07acd730",
            "213afabd53af495c8f83ae9f1c26febb",
            "bd5cee99e3a54d66af6847f47ac6ab55",
            "99d2c0833c19444e8ab98ef4a2cb11c8",
            "d5e27627ffd84dd1b63010ad1daabfde",
            "76a5311597d042268f7c946308762f9c",
            "ea736852d2b84c17bbc771438f6920ac",
            "626781fb818f45d5832170c5f829ee10",
            "81a84dffaa6c49199ac1abeb3ba62a63",
            "e7cb90886355466085cf66ad8f44e160",
            "fe0a6d565f3b403dbb66d775c7e189af",
            "d43756d0b116419ba552455db87417df",
            "7e78d2258d7346b3ab7595f22ecb8205",
            "7f4b370603c84962913f9b66d8ec2586",
            "488d9a5010a24efeb6985506a0bef4d8",
            "a0ef15b3c55b4200a45e3eead2792354",
            "fd3891f787c54f83b820f62404ecabc0",
            "0e2d6d03bb7c40f18c1a46ed99da73c3",
            "18e8ea145f89464aac7b163afd2b9dfc",
            "de496407a2bc4fb98eedca6706f5b429",
            "fa591e825d5442aa9639a4568ad02552",
            "6db2c06e51f5402b8137039c82af0803",
            "da46b503a7e24d6bae1ff5db3681868d",
            "92c3e4225dab40c89182c2611cd71ed7",
            "d59eb19543b245c4a9cc493ee6772329",
            "e730b6bcbba942c09256130d68f77f71",
            "401e4c08170f4aa48ce605fa6a3ee1b6",
            "978f73bf9b3548b89e57849227ccd8d8",
            "4347ed40174040eb89aad90e43ef1112",
            "688af4afda9e41148ad54e99a8731724",
            "d40b00a3c2704c1f8cb27fc49046e974",
            "e345ba1383a549f9b074399c1042579d",
            "fafd37af020147c9905812e86a2b644a",
            "0e5db9f2e1624bf19d7d3a7586245423",
            "37b2a31550e14436b8420e3424a93999",
            "745942be41a740a6a911e259f0c9d194",
            "6ce0bdecef1b4ddd9f9f77b0ee1e62d7",
            "3c53c2bb33944ed89baab45e3c5bea6c",
            "97facc0b5dbd4965bb39322f93665a02",
            "bb99ed57ebdd458fae1a48106352dd3a",
            "0e9b28fa3c454a7baaa78d2ee523c792",
            "5e1a9e1ebf954a269bcd50f033dfc43c",
            "fd68d0871911447c93358ff464c866b4",
            "3baad48d4ced432585a62918d442ca6e",
            "b04de71694544085b531e09e6def6f3d",
            "7cbbdb94212748e6911ac9d30eba34a0",
            "1f518014fc7a44f790b1b446a247894a",
            "1b30d8ea3fea4a5ab2cc21ce756fc6bd",
            "94d59bfa446046c9af2c67620135a20a",
            "45c5318e9cf842d4817cd8b117ff4e03",
            "b267c6bf27ef4d0c8fb7f7fc112368af",
            "5130fcd0504a409699da09d47bf1d537",
            "c065db433d76453b94826e15d245eb2b",
            "8163c2c78cb0437d952ad00574e076a9",
            "bef9fdb11d25408cbfeaadb8d01bd69f",
            "27eb19b261114aaab0253d9afa0ff439",
            "865b0e1763b04ddb81aeff8f918eef24",
            "6572dd645f7f4ef9bad2c1ba83526c79",
            "503c8783e9654b3f89b5ec8d5f635619",
            "c277d723381b4bbbb1bb8646501ceb05",
            "2dd7f51aa6b4455e8f653c7ff0c40d0e",
            "3c5de0a98f114053be462ef884523a9f",
            "7502f625c49d48dd8a524ee36a599db6",
            "576e7e389c6d48cebcf0e00784cc8710",
            "a4d594638dd142819603b19ddf1de4f3",
            "bc86582d71be47d8982fbf17a6b88f45",
            "222fe2ed179f4189b000396d04d09453",
            "be9d953a535c4092aa0c0948040b1976",
            "0ed2519972754db6ba02a0e10a9bdee8",
            "b7b87f0ec3ee42a8b8d5796851df3dee",
            "b182eccbd659427cb3beebe38c059747",
            "bf32f383e1b9434f85c94bb49964ee08",
            "0e19e287e06d4c4d9183fe019601a70a",
            "8160e15f48b64f9ea474656adc81f579",
            "796b854a480248c498b22eb79cc3cf79",
            "4fb57ef81d304ad190432e272e4e94bf",
            "ce3b3f1c16e74050b212627e1831fb45",
            "9ef5a50ad6644535a5ffea66da7c84f5",
            "1bc35ad64b594245b0c07bdba57eb1c6",
            "73fea98782484662827520c5c2998ec2",
            "a6507ac8b8404e698dbd364256b6baab",
            "bc4b38d311594dd1b0bdf80e21f17b41",
            "e9d1fe4f52d947348942844eddb0c537",
            "43ad8c39f74e43568140540f37b84e0a",
            "463b2fa34dee496a98718b0b1ae8eecc",
            "b8763e22f8594f7a9e43eeb86a502be3",
            "ae57381c7ebe4a4e87d120bddc8693df",
            "3c560c77c66343649c063acf259c73e9",
            "12c21db243c741839f3d48c712545be8",
            "f513ff2903a84881842ac7762ccc4f38",
            "cdf1a83a2d6348fa9160f2f7cd676813",
            "28997092dee041688460f0fe077e48de",
            "9b2e793087c648d08201578a7a4e1f37",
            "5a7a2425094e4c1a9f6caf522eb9a64f"
          ]
        },
        "id": "27TJGTZfavys",
        "outputId": "5fa5455e-4ec3-4c35-b6b8-870f0607727b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce6b242414a543c2a12ed96d0b172e6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d90731d190b146b29cf1cc0ce7371f76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8c4b5d46b534647b56e28be51c71143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a72c1a13a5ad428188e3152be9096148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acb46db6a67a4ff1a9c76dff39cd96b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "812e1f6d4aa849e49df5a04e9786720e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea736852d2b84c17bbc771438f6920ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e2d6d03bb7c40f18c1a46ed99da73c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4347ed40174040eb89aad90e43ef1112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb99ed57ebdd458fae1a48106352dd3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b267c6bf27ef4d0c8fb7f7fc112368af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c5de0a98f114053be462ef884523a9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e19e287e06d4c4d9183fe019601a70a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43ad8c39f74e43568140540f37b84e0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.25026105e-02 -7.82917812e-02 -2.30307486e-02 -5.10006677e-03\n",
            " -8.03404450e-02  3.91321294e-02  1.13428580e-02  3.46483383e-03\n",
            " -2.94574704e-02 -1.88930072e-02  9.47434008e-02  2.92747878e-02\n",
            "  3.94859761e-02 -4.63165939e-02  2.54246294e-02 -3.21999453e-02\n",
            "  6.21928424e-02  1.55591788e-02 -4.67795618e-02  5.03902026e-02\n",
            "  1.46113662e-02  2.31413934e-02  1.22066885e-02  2.50696652e-02\n",
            "  2.93654157e-03 -4.19822149e-02 -4.01036721e-03 -2.27843709e-02\n",
            " -7.68588809e-03 -3.31090614e-02  3.22118513e-02 -2.09992286e-02\n",
            "  1.16730649e-02 -9.85073894e-02  1.77932623e-06 -2.29931846e-02\n",
            " -1.31140910e-02 -2.80222818e-02 -6.99970722e-02  2.59314068e-02\n",
            " -2.89501362e-02  8.76336619e-02 -1.20919012e-02  3.98605317e-02\n",
            " -3.31382118e-02  3.59108336e-02  3.46099064e-02  6.49783984e-02\n",
            " -3.00817713e-02  6.98187873e-02 -3.99513636e-03 -1.01600029e-03\n",
            " -3.50185446e-02 -4.36567441e-02  5.08025587e-02  4.68757823e-02\n",
            "  5.39663173e-02 -4.03008349e-02  3.20139038e-03  1.36618130e-02\n",
            "  3.82188670e-02 -3.23845353e-03 -7.84586358e-04 -1.71188749e-02\n",
            "  6.90439763e-03 -1.09237283e-02  8.63304827e-03 -1.82357989e-02\n",
            "  1.87930949e-02  1.54990433e-02  1.02150096e-02 -2.48378026e-03\n",
            "  1.03153428e-02  6.24887235e-02  3.60318157e-03 -6.26622839e-03\n",
            " -2.03405824e-02 -6.72353199e-03 -3.54771353e-02  3.43538225e-02\n",
            "  6.72282279e-02  9.06873122e-02  1.32441204e-02  2.06592660e-02\n",
            " -2.78685652e-02  4.29694653e-02 -4.66859490e-02  1.50115648e-02\n",
            " -6.62284419e-02 -2.27593333e-02 -6.24990501e-02 -2.58455854e-02\n",
            "  7.31309759e-04  1.14652757e-02  5.66383563e-02  2.06243643e-03\n",
            " -4.09248956e-02 -4.55051363e-02  1.66958347e-02 -8.31556916e-02\n",
            "  2.09066248e-03 -8.70916713e-03  1.07622531e-04  3.37445401e-02\n",
            "  5.60348202e-03 -1.66981556e-02  4.47909161e-02  6.31808676e-03\n",
            " -6.45904094e-02  5.29103652e-02  1.93019174e-02 -6.20153546e-03\n",
            " -1.18759967e-01  3.55963521e-02 -2.28864700e-02 -1.51872300e-02\n",
            " -5.92663838e-03 -1.57189439e-04  1.07069639e-02  3.86085082e-03\n",
            " -6.87015131e-02 -1.69752520e-02 -2.79730130e-02  2.80480720e-02\n",
            "  2.47793999e-02  1.20279342e-02 -6.86393678e-02  4.92765270e-02\n",
            "  1.87576562e-02 -2.42343470e-02 -2.05291603e-02 -1.07933935e-02\n",
            "  2.46493109e-02 -3.33323255e-02 -3.28397714e-02  2.91978326e-02\n",
            "  4.92032953e-02 -7.13365059e-03 -1.63389966e-02  1.78588438e-03\n",
            "  2.18068287e-02 -8.90231207e-02 -3.37051526e-02  5.77225955e-03\n",
            " -4.56566028e-02  3.39890830e-02  3.52784172e-02 -3.12627852e-02\n",
            "  8.10833368e-03  2.68614888e-02 -2.23898538e-03  2.81266645e-02\n",
            " -1.75383687e-02 -1.44589972e-02 -3.33480649e-02 -1.62954535e-02\n",
            "  9.70038474e-02 -8.11068807e-03 -2.46668626e-02 -5.87456338e-02\n",
            "  8.74859048e-04  1.67235136e-02  9.15385224e-03 -1.17982854e-03\n",
            " -2.93020299e-03  4.22467012e-03 -2.16529295e-02  4.29305658e-02\n",
            " -5.86095639e-02  3.13417837e-02 -1.29514618e-03 -1.11297900e-02\n",
            " -2.82019954e-02  8.77324268e-02  2.06880849e-02  1.41398599e-02\n",
            "  1.38229392e-02 -1.94184072e-02 -9.01035592e-02 -3.81481717e-03\n",
            " -2.91159120e-03  3.09753716e-02 -1.18769128e-02  1.88289359e-02\n",
            " -4.59066592e-02  4.98210378e-02 -8.39177426e-03 -4.29713912e-02\n",
            " -3.23598869e-02 -3.83801050e-02 -2.99748089e-02  3.69881578e-02\n",
            " -4.44587693e-03 -1.94783807e-02 -2.71527953e-02  2.43246574e-02\n",
            "  9.16432648e-04  5.85004650e-02  1.92714110e-02 -2.57291254e-02\n",
            "  4.08677757e-02  4.36860975e-03  5.13519682e-02  1.57081001e-02\n",
            " -2.46329512e-02 -9.79607087e-03  2.06120592e-03 -4.66644503e-02\n",
            "  3.19585130e-02 -3.73425782e-02  9.35152546e-02  1.85420625e-02\n",
            " -2.60215215e-02  8.05765949e-03 -6.38655110e-05 -4.74144192e-03\n",
            "  2.17362121e-02 -4.03623767e-02 -3.97234857e-02  6.60505667e-02\n",
            " -3.20185497e-02 -1.52356476e-02 -1.53095610e-02  5.58152422e-03\n",
            "  3.96784805e-02 -5.98881058e-02 -2.94910409e-02 -1.53479623e-02\n",
            " -3.32981646e-02 -1.35856112e-02 -2.23695319e-02  1.81127386e-03\n",
            " -2.53541162e-04  7.30925612e-03 -4.96328436e-02  3.74633968e-02\n",
            " -4.42487337e-02 -8.77881870e-02 -1.95525587e-02 -7.44620636e-02\n",
            " -5.28368633e-03 -8.59958772e-03  1.65657997e-02  1.99179146e-02\n",
            " -9.94190574e-03 -2.85211089e-03  7.21454173e-02 -1.99029427e-02\n",
            "  2.95140687e-02 -5.97201101e-02  5.00880927e-02 -2.54911277e-02\n",
            "  2.33916380e-02 -7.12675927e-03  7.38673843e-03 -7.17939511e-02\n",
            "  9.14931181e-04  2.19873618e-02  4.15909849e-03  1.79544166e-02\n",
            "  6.32213429e-02 -2.47941306e-03 -5.26579702e-03  2.34971251e-02\n",
            " -2.61955392e-02 -3.71229760e-02  2.15678625e-02 -5.85354753e-02\n",
            " -1.79577656e-02 -1.20005067e-02  8.96505371e-04 -1.47689646e-02\n",
            "  4.96945046e-02  6.97954511e-03  2.64367871e-02  4.61773984e-02\n",
            "  3.20433900e-02 -3.66005749e-02 -5.08421147e-03  6.88665509e-02\n",
            "  5.68004549e-02 -1.46777891e-02 -4.78474945e-02  1.21871624e-02\n",
            " -2.50420682e-02  3.12442705e-02 -1.79439709e-02 -3.05826534e-02\n",
            "  1.71711482e-03  7.02126697e-02  5.67383356e-02 -1.79368444e-02\n",
            "  2.44000461e-02 -2.86525823e-02 -1.15867341e-02 -2.70408653e-02\n",
            "  3.95130739e-02  4.29957323e-02  2.90972665e-02  2.80838665e-02\n",
            " -4.62749004e-02 -4.28294344e-03  1.19901923e-02 -1.20225055e-02\n",
            " -9.46940668e-03  2.35066321e-02 -3.00627723e-02 -1.69607922e-02\n",
            " -1.59735780e-03 -1.30610745e-02  5.35884537e-02  2.53782943e-02\n",
            "  2.60250214e-02  6.27413169e-02 -2.26463489e-02  6.58663781e-03\n",
            " -3.48779149e-02 -8.88994616e-03 -3.32266763e-02 -1.81600042e-02\n",
            " -6.45450130e-03  1.02021480e-02 -1.25164455e-02  4.20163833e-02\n",
            "  1.12152118e-02 -2.13345438e-02  1.05621023e-02  1.99820623e-02\n",
            "  1.83803663e-02  3.29687330e-03 -8.70438199e-03  1.90762375e-02\n",
            " -4.41013798e-02  9.57715064e-02  2.73615494e-02  1.76533926e-02\n",
            " -2.20417902e-02  3.70631181e-02 -6.52673829e-04 -1.44511405e-02\n",
            "  1.09791057e-02 -8.40490591e-03 -3.26196663e-03 -2.20720582e-02\n",
            " -1.90347321e-02 -1.60558317e-02 -4.08147462e-02  1.11608980e-02\n",
            " -6.02423064e-02 -6.96681440e-02 -1.73304286e-02  2.87935063e-02\n",
            " -6.79623261e-02 -3.13759185e-02 -5.51356189e-02 -2.03582626e-02\n",
            "  2.89012939e-02  1.37794334e-02  6.80509256e-03 -2.43214075e-03\n",
            "  7.21530691e-02 -1.17461092e-03 -3.57215330e-02  3.54786627e-02\n",
            " -1.96368992e-03 -7.76637578e-03  3.01939212e-02  1.85422022e-02\n",
            " -5.39994203e-02  3.32430005e-02  5.73030580e-03  1.33993253e-02\n",
            "  4.51613218e-03  4.88920286e-02 -3.14347446e-02  3.62168700e-02\n",
            "  3.65449227e-02 -4.79209833e-02 -1.44876121e-02  4.93125841e-02\n",
            "  2.86978576e-02 -5.51462993e-02  2.74743754e-02  1.27805080e-02\n",
            " -7.04631954e-02  7.69067788e-03 -5.24687488e-03 -5.33922538e-02\n",
            " -1.70809068e-02  4.77676727e-02  2.38064751e-02 -4.09796834e-02\n",
            " -1.27406456e-02  4.66342606e-02  5.03483275e-03  6.60549244e-03\n",
            "  2.90571749e-02  4.15973850e-02 -3.82126570e-02 -1.14388242e-02\n",
            "  1.71640404e-02  5.70876896e-03  1.07285557e-02 -1.80592891e-02\n",
            " -5.06379642e-02  4.54925112e-02  1.40737975e-02  4.25583534e-02\n",
            " -3.22351381e-02  4.17672545e-02  1.14987167e-02  3.92396189e-03\n",
            "  2.04459541e-02  1.52545655e-02  3.80402952e-02  2.54581142e-02\n",
            " -4.69273888e-03  1.83214862e-02  2.76016016e-02 -2.89157182e-02\n",
            " -4.98981029e-02 -1.61939599e-02  9.87022594e-02 -4.26361598e-02\n",
            " -1.88477784e-02 -1.07012223e-02 -3.21414992e-02  4.15321887e-02\n",
            " -2.38699317e-02  8.39931890e-03 -1.00904342e-03 -3.11340764e-02\n",
            " -3.86489555e-02 -3.06742564e-02 -3.88901010e-02 -3.65616418e-02\n",
            "  3.29426234e-03  2.00938229e-02  2.30732132e-02 -4.77465726e-02\n",
            "  8.55968427e-03  2.21940782e-02  1.49231181e-01 -1.91771667e-02\n",
            "  1.43476771e-02  4.39949259e-02 -2.27761455e-03  1.38106837e-03\n",
            "  3.23159546e-02  6.57535046e-02  2.26997174e-02  2.18100566e-02\n",
            " -3.00688799e-02  1.54186003e-02  6.95953593e-02 -3.88419256e-02\n",
            " -1.09261841e-01 -7.51075475e-03  1.19599300e-02  1.27546946e-02\n",
            "  1.89590026e-02  4.54232544e-02 -4.60909568e-02 -5.17163519e-03\n",
            " -1.17528420e-02 -8.67661461e-03 -2.08859164e-02  4.49374653e-02\n",
            "  1.55425165e-02  1.32864323e-02 -3.67461070e-02  1.40869608e-02\n",
            "  2.77769612e-03  2.77871569e-03  2.99189389e-02 -3.01352236e-02\n",
            " -4.63992320e-02 -5.60871176e-02 -7.94625655e-03  3.58322971e-02\n",
            " -2.37628780e-02  3.04555744e-02  4.38166270e-03 -1.49128651e-02\n",
            " -2.00193264e-02  4.84519498e-03 -1.40724308e-03 -3.53151783e-02\n",
            "  5.58816316e-03  7.45548820e-03  1.51486322e-03  4.03528959e-02\n",
            " -6.45007240e-03 -2.26507522e-03 -3.91197763e-02  1.05104009e-02\n",
            "  1.14451451e-02  2.85172798e-02  2.43227556e-02 -8.16608518e-02\n",
            " -4.06114198e-02  4.48722541e-02  5.76137041e-04  3.66367325e-02\n",
            " -5.07901460e-02  3.42644639e-02  2.49840431e-02  1.17401816e-02\n",
            "  1.71504728e-02  2.12810859e-02 -1.83074046e-02 -5.08700162e-02\n",
            " -1.79200135e-02  2.44995952e-02 -8.84231925e-03  1.70267001e-02\n",
            " -2.69820332e-03 -7.86308125e-02  5.88882305e-02  2.79413257e-03\n",
            "  1.18669588e-02 -3.29489037e-02  2.49917451e-02 -3.39025483e-02\n",
            " -7.46754035e-02  2.85451533e-03 -4.59519448e-03  1.36553159e-03\n",
            " -6.91541284e-02  3.54953320e-03 -1.40170781e-02  6.54011965e-03\n",
            " -5.49735799e-02  4.28331271e-02 -5.33593819e-02  3.18162329e-03\n",
            "  1.04328476e-01  3.42741832e-02  4.07343768e-02  1.89621169e-02\n",
            "  2.44271345e-02 -1.29663236e-02  6.00200221e-02  3.92833129e-02\n",
            "  7.58032501e-02 -1.51843037e-02 -7.98326451e-03  3.47589590e-02\n",
            " -1.86614431e-02 -6.96071684e-02 -7.13097826e-02  2.77238674e-02\n",
            " -3.20368260e-02  3.10048386e-02  1.26677367e-03 -6.69391282e-33\n",
            " -3.91474403e-02 -3.46212387e-02  2.06935778e-03  6.21102452e-02\n",
            " -4.16611731e-02 -9.90154594e-03 -1.67432912e-02  7.94497877e-03\n",
            " -1.07789366e-03  2.85014603e-02 -3.19683515e-02  1.79135089e-03\n",
            "  3.13649923e-02 -1.40697183e-02  1.93634741e-02  7.51152541e-03\n",
            "  3.52904573e-02 -1.16606001e-02 -2.80548539e-03 -1.19964583e-02\n",
            " -2.97140013e-02 -1.76579859e-02  4.52528372e-02 -1.38789078e-03\n",
            " -7.87150115e-03 -8.17415398e-03 -5.47759943e-02 -1.12036504e-02\n",
            " -6.26672581e-02 -2.15537511e-02  5.16278902e-03 -2.60673836e-02\n",
            " -1.97687224e-02 -2.41160616e-02 -3.39965038e-02  4.55973595e-02\n",
            " -5.38011733e-03 -5.15832677e-02  2.78135575e-02  3.86534072e-02\n",
            " -9.17188749e-02 -5.43298721e-02 -2.38128733e-02  8.47349130e-03\n",
            " -2.56151073e-02 -1.94259360e-02 -5.79075143e-03 -3.53576466e-02\n",
            "  3.68123390e-02 -4.75911945e-02 -3.93513031e-02  1.03632116e-03\n",
            " -3.56920063e-02  4.05900814e-02 -3.41656338e-03  2.35696733e-02\n",
            " -1.65533759e-02 -1.51567149e-03 -4.22695316e-02  1.85887199e-02\n",
            "  4.51937914e-02  5.00864275e-02 -3.62452343e-02 -3.38022299e-02\n",
            " -2.15227026e-02  7.74866203e-03  3.47937783e-03  8.42259964e-04\n",
            "  1.18840542e-02  6.97644129e-02  8.02960619e-03  1.04670994e-01\n",
            " -4.34278287e-02  1.09933428e-01  2.27689110e-02 -3.14176716e-02\n",
            " -1.14897247e-02 -3.55337770e-03  2.82175746e-02 -1.62151773e-02\n",
            "  6.32874072e-02  1.12804994e-02 -4.53989916e-02 -4.23893034e-02\n",
            " -4.77063954e-02 -4.93459851e-02 -3.72873875e-03  3.38707753e-02\n",
            " -3.09105664e-02  2.06780955e-02  3.08634639e-02  6.29141927e-02\n",
            "  1.70472413e-02 -1.72119737e-02 -3.77116762e-02  3.45212556e-02\n",
            " -4.09610458e-02  4.88860020e-03 -3.00612859e-02 -8.41373205e-03\n",
            " -4.09953408e-02 -3.98016386e-02 -5.39269708e-02  1.65643226e-02\n",
            "  5.96864633e-02  3.61519642e-02  4.98929434e-02  1.44996960e-02\n",
            " -1.09169647e-01 -1.43747777e-02 -1.36371404e-02  1.62526611e-02\n",
            " -1.17083022e-03 -3.09679247e-02 -2.90011670e-02 -6.66360091e-03\n",
            "  9.04127210e-03  4.31807078e-02 -2.07463764e-02 -5.69087304e-02\n",
            " -2.79608257e-02  4.16314267e-02 -6.23094812e-02  2.17974558e-02\n",
            "  2.10569706e-03  1.54057145e-02  3.57554592e-02  2.54537668e-02\n",
            "  3.60637307e-02 -7.28387386e-02 -5.19865798e-03 -2.23384076e-03\n",
            "  2.51205535e-07  4.48065810e-03  6.26780018e-02  2.36657560e-02\n",
            "  6.45827726e-02  1.77587382e-02  4.13445123e-02 -3.67186777e-02\n",
            "  5.56979366e-02 -4.12960202e-02  3.65489423e-02  7.52831250e-02\n",
            " -3.72790918e-02 -2.12006606e-02 -1.76452193e-02 -2.88425889e-02\n",
            "  2.56824382e-02 -4.92919497e-02 -8.79911706e-02 -2.83660907e-02\n",
            " -2.19023824e-02  3.70794572e-02  4.11573872e-02  7.84277022e-02\n",
            " -1.48525024e-02  6.14955137e-03 -4.01153080e-02 -2.02855784e-02\n",
            " -2.90953107e-02  6.01130677e-03  3.68368812e-02  7.31773721e-03\n",
            " -8.81806388e-03  4.70298436e-03  3.01264301e-02 -3.82546335e-03\n",
            " -6.81492174e-03  3.72341909e-02  8.78986120e-02 -2.90224631e-03\n",
            "  3.33461538e-02 -3.84543575e-02 -5.78215420e-02 -2.74080392e-02\n",
            "  1.45640485e-02  1.58608146e-02  1.84694398e-02  3.52275856e-02\n",
            " -5.63630909e-02  2.07085405e-02  3.22306342e-02 -2.99263597e-02\n",
            "  5.92910685e-02 -3.01268091e-03 -2.28289282e-03  2.80255172e-02\n",
            " -7.59407133e-02  4.06446075e-03  1.21565247e-02  1.28566260e-02\n",
            " -1.73889438e-03 -2.95145828e-02  3.77574824e-02  1.94634851e-02\n",
            "  4.80340496e-02  1.52997011e-02  5.04777767e-02 -8.81988462e-03\n",
            "  1.64886799e-34  4.77930494e-02 -6.48032781e-03 -3.31389811e-03\n",
            "  1.02901114e-02 -3.30803841e-02 -2.55397577e-02  3.78654376e-02\n",
            " -1.35550592e-02 -8.27930029e-03  2.65268721e-02 -2.01899465e-03]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the pretrained transformer model\n",
        "sentence_transformer_model = SentenceTransformer(\n",
        "    'sentence-transformers/{model}'.format(model=SENTENCE_TRANSFORMER_MODEL))\n",
        "\n",
        "# Sanity check\n",
        "example_encoding = sentence_transformer_model.encode(\n",
        "    \"This is an example sentence\",\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "\n",
        "print(example_encoding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "de0oQW1raJzY"
      },
      "outputs": [],
      "source": [
        "class TransformerFeaturizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, sentence_transformer_model):\n",
        "        self.sentence_transformer_model = sentence_transformer_model\n",
        "        # you can add any other params to be passed to the constructor here\n",
        "\n",
        "    #estimator. Since we don't have to learn anything in the featurizer, this is a no-op\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    #transformation: return the encoding of the document as returned by the transformer model \n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"\n",
        "        [TO BE IMPLEMENTED]\n",
        "        \n",
        "        Goal: TransformerFeaturizer's transform() method converts the raw text document\n",
        "        into a feature vector to be passed as input to the classifier.\n",
        "            \n",
        "        Given below is a dummy implementation that always maps it to a zero vector.\n",
        "        You have to implement this function so it uses computes a document embedding\n",
        "        of the input document using self.sentence_transformer_model. \n",
        "        This will be our feature representation of the document\n",
        "        \"\"\"\n",
        "        pool = self.sentence_transformer_model.start_multi_process_pool()\n",
        "\n",
        "        #Compute the embeddings using the multi-process pool\n",
        "        embeddings = self.sentence_transformer_model.encode_multi_process(X, pool)\n",
        "        print(\"Embeddings computed. Shape:\", embeddings.shape)\n",
        "\n",
        "        #Optional: Stop the proccesses in the pool\n",
        "        self.sentence_transformer_model.stop_multi_process_pool(pool)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1nwMri8aeFi",
        "outputId": "02c679a9-4af3-4107-e80c-00f3541b218a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating for training data size = 500\n",
            "Embeddings computed. Shape: (500, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.717\n",
            "Evaluating for training data size = 1000\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.74\n",
            "Evaluating for training data size = 2000\n",
            "Embeddings computed. Shape: (2000, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.75\n",
            "Evaluating for training data size = 5000\n",
            "Embeddings computed. Shape: (5000, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.767\n",
            "Evaluating for training data size = 10000\n",
            "Embeddings computed. Shape: (10000, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.771\n",
            "Evaluating for training data size = 25000\n",
            "Embeddings computed. Shape: (25000, 768)\n",
            "Embeddings computed. Shape: (1000, 768)\n",
            "Accuracy on test set: 0.789\n"
          ]
        }
      ],
      "source": [
        "models_v2 = {}\n",
        "for n in TRAIN_SIZE_EVALS:\n",
        "    print(\"Evaluating for training data size = {}\".format(n))\n",
        "    X_train_i = X_train[:n]\n",
        "    Y_train_i = Y_train[:n]\n",
        "\n",
        "    \"\"\"\n",
        "    [TO BE IMPLEMENTED]\n",
        "        \n",
        "    Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "    You have to replace it with a pipeline object which contains at least two steps:\n",
        "    (1) mapping the input document to a feature vector (using TransformerFeaturizer)\n",
        "    (2) a classifier that predicts the class label using the feature output of first step\n",
        "\n",
        "    You can add other steps to preproces, post-process your data as you see fit. \n",
        "    You can also try any sklearn model architecture you want, but a linear classifier\n",
        "    will do just fine to start with\n",
        "\n",
        "    e.g. \n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', <your TransformerFeaturizer class instance here>),\n",
        "        ('classifier', <your sklearn classifier class instance here>)\n",
        "    ])\n",
        "    \"\"\"\n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', TransformerFeaturizer(sentence_transformer_model)),\n",
        "        ('classifier', LogisticRegression(max_iter=LR_MAX_ITER))\n",
        "    ])\n",
        "\n",
        "    # train\n",
        "    pipeline.fit(X_train_i, Y_train_i)\n",
        "    # predict\n",
        "    Y_pred_i = pipeline.predict(X_test)\n",
        "    # record results\n",
        "    models_v2[n] = {\n",
        "        'pipeline': pipeline,\n",
        "        'test_predictions': Y_pred_i,\n",
        "        'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "        'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "        'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "    }\n",
        "    print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw89vQkE5woo"
      },
      "source": [
        "## Step 5: [Modeling part 3] Large Language Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "jSijGuIc5yX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b686f0ae-5673-456a-efe4-4b5ae99e9db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88957 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89886 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89730 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89618 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        }
      ],
      "source": [
        "# Here's a couple of code snippets to help you familiarize with how to generate labels with LLMs using langchain,\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import LLMResult, HumanMessage, Generation\n",
        "import tiktoken\n",
        "\n",
        "MODEL_NAME = \"gpt-3.5-turbo\" \n",
        "encoding = tiktoken.encoding_for_model(MODEL_NAME)\n",
        "\n",
        "def num_tokens_from_string(string, encoding_name = encoding) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "MAX_TOKENS = max(num_tokens_from_string(label) for label in LABEL_SET)\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=MODEL_NAME,\n",
        "    max_tokens=MAX_TOKENS,\n",
        "    temperature=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5-u93SS50ip",
        "outputId": "35b28c32-093e-450f-da75-d4d1954eed8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Negative' generation_info=None message=AIMessage(content='Negative', additional_kwargs={}, example=False)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "zero_shot_prompt_template = \"\"\"\n",
        "You are an expert at judging the sentiment of tweets. \n",
        "Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n",
        "\n",
        "Tweet: {tweet}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "prompt = zero_shot_prompt_template.format(\n",
        "    tweet=\"I hate machine learning\"\n",
        ")\n",
        "\n",
        "result = llm.generate([[HumanMessage(content=prompt)], [HumanMessage(content=prompt)]])\n",
        "print(result.generations[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OovRQRuE52Tm",
        "outputId": "a5b7f5d5-5bcc-4cef-8c04-e112f8ff7fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Positive' generation_info=None message=AIMessage(content='Positive', additional_kwargs={}, example=False)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "few_shot_prompt_template = \"\"\"\n",
        "You are an expert at judging the sentiment of tweets. \n",
        "Your job is to categorize the sentiment of a given tweet into one of three categories: Positive, Negative, Neutral.\n",
        "\n",
        "Some example tweets along with the correct sentiment are shown below.\n",
        "\n",
        "Tweet: Another big happy 18th birthday to my partner in crime. I love u very much!\n",
        "Sentiment: Positive\n",
        "\n",
        "Tweet: The more I use this application, the more I dislike it. It's slow and full of bugs.\n",
        "Sentiment: Negative\n",
        "\n",
        "Tweet: #Dreamforce Returns to San Francisco for 20th Anniversary. Learn more: http://bit.ly/3AgwO0H\n",
        "Sentiment: Neutral\n",
        "\n",
        "Now I want you to label the following example: \n",
        "Tweet: {tweet}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "prompt = few_shot_prompt_template.format(\n",
        "    tweet=\"I like chocolate\"\n",
        ")\n",
        "\n",
        "result = llm.generate([[HumanMessage(content=prompt)]])\n",
        "print(result.generations[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by3AxCi058qH"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import asyncio\n",
        "from asyncio import Semaphore\n",
        "\n",
        "class LLMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, llm_model, prompt_template, semaphore):\n",
        "        self.llm_model = llm_model\n",
        "        self.prompt_template = prompt_template\n",
        "        self.semaphore = semaphore\n",
        "\n",
        "    # This will be called during the training step\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    # This will be called during inference.\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        [TO BE IMPLEMENTED]\n",
        "\n",
        "        Goal: LLMClassifier's predict() method constructs the final prompt input\n",
        "        for the LLM for each x in X, using the prompt template.\n",
        "\n",
        "        You have to implement this function so it does the following:\n",
        "        1. Construct the final prompt for the LLM\n",
        "        2. Call `self.llm_model` to generate the completion (label) for the prompt\n",
        "        3. Do any post-processing/response parsing to fetch the label from the LLM response\n",
        "        \"\"\"\n",
        "        with get_openai_callback() as cb:\n",
        "          prompts = [\n",
        "              [[HumanMessage(content=self.prompt_template.format(article=document))]]\n",
        "              for document in X\n",
        "          ]\n",
        "          result = asyncio.run(self.__generate_labels(prompts))\n",
        "          print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "          print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "          print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "          print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
        "          print(result)\n",
        "          return result\n",
        "\n",
        "    async def __async_generate(self, prompt):\n",
        "        async with self.semaphore:\n",
        "          response = await self.llm_model.agenerate(prompt)\n",
        "          label = response.generations[0][0].text\n",
        "          print(label)\n",
        "          return label\n",
        "\n",
        "    async def __generate_labels(self, prompts):\n",
        "        tasks = [self.__async_generate(prompt) for prompt in prompts]\n",
        "        labels = await asyncio.gather(*tasks)\n",
        "        return labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_article_zero_shot_template = \"\"\"\n",
        "You are an expert at judging the category of which a news article belongs too. \n",
        "Your job is to categorize the category of a given article into one of three categories: Sci/Tech, Software and Developement, Entertainment, Sports, Health, Toons, and Music Feed.\n",
        "\n",
        "Article: {article}\n",
        "News article category:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pZGEVgBJnC94"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVemE-2R5-xN",
        "outputId": "0e9dc0d2-d878-43dd-fb00-2eae8273c4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89045 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sports\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Economy/Finance\n",
            "Sports\n",
            "Politics/Current Events\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Business/Finance\n",
            "Sports\n",
            "None of the above categories. This article belongs to the category of World/International News or Politics.\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Business/Finance\n",
            "Entertainment\n",
            "Health\n",
            "Business/Economy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports (possibly political\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89160 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics/Current Events\n",
            "Politics/Current Events\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88953 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Politics/Economics\n",
            "Economics/Business\n",
            "Crime/Justice\n",
            "Sports\n",
            "Music Feed\n",
            "Politics\n",
            "Business/Economy\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89386 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Health\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88988 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88926 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Software and Development\n",
            "Music Feed\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89091 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Finance/Economy\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88984 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89340 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employment and Labor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88996 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89194 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "This news article belongs\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89471 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89360 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Software and Development\n",
            "Sports\n",
            "Entertainment\n",
            "Finance/Business\n",
            "Politics/Law\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88952 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89015 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88921 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88980 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 168af955c637bcbca9c83571c4b7b45d in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/World News\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89024 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Politics/Current Events\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88969 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88888 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Entertainment\n",
            "Politics\n",
            "Software and Development\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89069 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89895 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89170 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89697 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trade/Economy\n",
            "Sports\n",
            "Politics/Government\n",
            "Politics\n",
            "Sports (incorrect categor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89252 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89911 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89229 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Politics/Elections\n",
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89190 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Economics/Finance\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89596 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89518 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89055 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None of the above\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89177 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Animals and Wildlife\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89085 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89583 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89104 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather/Natural Dis\n",
            "Sci/Tech\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89850 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics/Law\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89290 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Politics/International Relations\n",
            "Music Feed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89802 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sci/Tech (as it involves government contracts and investigations)\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88954 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89759 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a833d55d4e979338797a086a582e1e5e in your message.).\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Business/Finance\n",
            "Sports\n",
            "Entertainment\n",
            "Software and Development\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89453 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics/International Affairs\n",
            "Politics/Law\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89171 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software and Development\n",
            "Business/Economy\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Business/Economy\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Politics\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88921 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89160 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Business/Economy\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89145 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Music Feed\n",
            "Obituary/\n",
            "Sports\n",
            "Sports\n",
            "Politics\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89110 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "None of the given\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89765 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89568 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics or World News\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Toons\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89136 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89018 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Software and Development\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89262 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89152 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88937 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports (This article\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Business/Finance\n",
            "Politics/Current Events\n",
            "Health\n",
            "Politics/International Affairs\n",
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89038 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Finance/Investment\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89087 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "I'm sorry,\n",
            "Sci/Tech\n",
            "Health\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Sports (This is\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech or\n",
            "Music Feed\n",
            "Entertainment\n",
            "Economics/Business\n",
            "Finance/Economy\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88966 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89223 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Toons\n",
            "Retail/Sales\n",
            "Sports\n",
            "Entertainment\n",
            "Labor/Employment (not one of the given categories, but closest match would be Business/Finance)\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88929 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Toons\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Finance/Business\n",
            "Entertainment\n",
            "Health (due to\n",
            "Business/Finance\n",
            "Sports\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89072 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "None of the above\n",
            "Business/Finance\n",
            "Sports\n",
            "Entertainment\n",
            "None of the above categories. This article falls under the category of World News or Current Events.\n",
            "Health\n",
            "Science/Technology (Sci/Tech)\n",
            "Politics/LGBTQ+ Rights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88966 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e14d33ef6eb3ea32cf16dbe6c4d5c80 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89228 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health (as it pertains to the safety and well-being of Nepalese workers)\n",
            "It is difficult to determine the category of this news article based on the given information. It could potentially fall under the category of Crime or Law Enforcement.\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89155 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/International Affairs\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bfbc0d707adade9a4fe3b0b732b1ddf4 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89089 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89012 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89075 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "This news article falls under the category of Crime or Law and Order. It does not fit into any of the given categories.\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89780 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89141 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89059 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89282 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Finance/Economy\n",
            "Politics/International Affairs\n",
            "Sports\n",
            "Business/Economy\n",
            "Health\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89071 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89848 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89410 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Weather/Natural Disaster\n",
            "Sports (incorrect category) \n",
            "\n",
            "Correct category: None of the given categories fit this news article. It is related to airport security and does not fall under any of the provided categories.\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Health (as the article is related to the safety and well-being of individuals in a conflict zone)\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Economy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b866f49b4a0e5350027a536ac0bdde94 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Music Feed\n",
            "Health\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89208 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88962 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "None of the above\n",
            "Sci/Tech\n",
            "Health\n",
            "Health (due to\n",
            "Business/Finance\n",
            "Music Feed\n",
            "Health\n",
            "Sports (This is not a news article, but if it were, it would likely fall under the category of war or conflict, which is not one of the given categories.)\n",
            "Sci/Tech\n",
            "Sports\n",
            "Finance/Business\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89099 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89057 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89221 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88941 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charity/Fundraising (not one of the given categories)\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89060 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Business/Economics\n",
            "Sci/Tech\n",
            "Natural Disasters/Weather\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88947 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Finance/Business\n",
            "Sci/Tech\n",
            "Politics/International Affairs\n",
            "Sports (as it pertains to military action and conflict)\n",
            "Politics\n",
            "Retail/Sales\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Economics/Business\n",
            "Politics/Economics\n",
            "Sci/Tech\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b04fa09237d25c71b384696dfb30af83 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Politics/Elections\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89253 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 91df1ae147cb923218fc754fc0ce19d5 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toons\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88950 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Economy/Finance\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Business/Economy\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Business/Finance\n",
            "Health\n",
            "Sports\n",
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88936 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Health\n",
            "Sports\n",
            "Health\n",
            "None of the above\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech or Software and Development (depending on the focus of the article)\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89011 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Economics/Business\n",
            "Sports\n",
            "Business/Economy\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e07cf523f8bf26ee57e031b01f0fd8ec in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89205 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Politics/Current Events\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89318 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Finance/Business\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88966 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Politics/Economics\n",
            "Politics\n",
            "Politics/World News\n",
            "Sports\n",
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89109 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89095 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89019 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Politics\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89205 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech\n",
            "Politics\n",
            "Finance/Economy\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89250 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Politics/Law\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88929 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Music Feed\n",
            "Sci/Tech (\n",
            "Sci/Tech\n",
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "Sports\n",
            "Finance/Business\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89260 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89127 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sports\n",
            "Politics/International Affairs\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89265 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Sports (as the article is likely discussing the attack on Pearl Harbor, which is a historical event related to war and military action)\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89102 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "I'm sorry,\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89231 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89103 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "It is difficult to\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89384 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89266 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/International Affairs\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88930 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finance/Economy\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89093 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89539 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None of the above. This article does not fit into any of the given categories. It may fall under the category of \"human interest\" or \"local news.\"\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88981 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Travel/Tourism\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89381 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89104 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/Elections\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88958 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89361 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/International Affairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89148 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d227e22312495b4888a4eb7d2c2df059 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Finance/Economics\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89826 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89173 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89688 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89190 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Economics/Business\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89271 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89438 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Toons\n",
            "Health\n",
            "Labor/Employment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89138 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Business/Finance\n",
            "Politics\n",
            "Health (as it pertains to the regulation of alcoholic beverages)\n",
            "Sports\n",
            "Finance/Business\n",
            "Entertainment\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88896 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None of the above\n",
            "Health\n",
            "Science/Technology (\n",
            "Security/Politics\n",
            "Politics/LGBTQ\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89926 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89192 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e7ba1c9f70f16f5f910ba13cd56a391 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Finance/Investment\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89286 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health (as it\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Politics/International Affairs\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "This news article falls\n",
            "Finance/Economy\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89275 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Finance/Economy\n",
            "Health\n",
            "Sports\n",
            "Politics/Current Events\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89228 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Sports (incorrect category\n",
            "Health\n",
            "Health\n",
            "Health (as the\n",
            "Sci/Tech\n",
            "Music Feed\n",
            "Sports (incorrect categorization) \n",
            "\n",
            "Correct categorization: International Affairs/Politics\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89104 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports (This is\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89181 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charity/Fundra\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Politics/Economics\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89132 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech (\n",
            "Health\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Politics/Elections\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88964 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6222bec1e7d79eb8529f2764890ec6ab in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Business/Economics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Natural Disasters/\n",
            "Business/Finance\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Economics\n",
            "Sci/Tech\n",
            "Finance/Business\n",
            "Sci/Tech\n",
            "Politics/International Affairs\n",
            "Sports (as it\n",
            "It is difficult to determine the exact category of the given article without more context. However, based on the keywords \"neat idea\" and \"price,\" it could potentially fall under the Sci/Tech or Software and Development categories.\n",
            "Politics\n",
            "Entertainment\n",
            "Retail/Sales\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88888 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Politics/World News\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89473 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89042 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Economics/Business\n",
            "Politics/Economics\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89441 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89150 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Politics/Elections\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89698 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89048 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Business/Finance\n",
            "Business/Finance\n",
            "Sports\n",
            "Sci/Tech or\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/Current Events\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Politics/Economics\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88908 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Economy\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89841 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "I'm sorry,\n",
            "Finance/Business\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports (as the\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Finance/Economy\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "None of the given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3af36cece42c31983265726d0afc6c6 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Politics/International Relations\n",
            "Sports\n",
            "Energy/Commodities\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Finance/Economy\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Music Feed\n",
            "Crime/Local News\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdb28348df34708799340103c65e46ad in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Politics\n",
            "Sports\n",
            "Politics/Government\n",
            "Business/Finance\n",
            "Business/Finance\n",
            "Politics/International Affairs\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "None of the above (this is just a schedule of events, not a news article with a specific category)\n",
            "Health\n",
            "Health\n",
            "Business/Finance\n",
            "Software and Development\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89058 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88951 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e77ca7c5a26b601ca3cd9d9b6ad2bfe1 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89376 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Politics/Elections\n",
            "Finance/Business\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88914 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Travel/Tourism\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sports\n",
            "Politics\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89014 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89015 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics\n",
            "Sports\n",
            "Finance/Economics\n",
            "Business/Finance\n",
            "Politics/International Affairs\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89609 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89150 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89877 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89182 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89182 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics/International Affairs\n",
            "Entertainment\n",
            "Business/Economy\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Economy\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88960 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports (incorrect categorization) \n",
            "\n",
            "Correct categorization: Weather/Natural Disaster or Current Events/Politics\n",
            "Health (as it\n",
            "Sports\n",
            "Finance/Business\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89078 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Security/Politics\n",
            "Toons\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88865 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Entertainment\n",
            "Business/Finance\n",
            "None of the given categories fit this article. It could potentially fall under the category of \"World News\" or \"Politics.\"\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89133 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89096 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89189 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Finance/Economy\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics/Current Events\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89168 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports (incorrect categor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89291 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88967 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics/Economics\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89158 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Politics/Elections\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89149 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89048 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Business/Economics\n",
            "Toons\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89201 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88987 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Music Feed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89115 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/World News\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89270 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88879 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Employment and Labor Force (not one of the given categories)\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88981 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech (related to international trade and sanctions)\n",
            "Politics/Government\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Politics/Elections\n",
            "Politics/Diplom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89242 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88924 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Energy/Commod\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n",
            "Legal/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89223 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finance/Economy\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Music Feed\n",
            "Crime/Local News\n",
            "Science/Technology\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89688 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/International Affairs\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89100 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89245 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89244 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech (\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88988 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "None of the above\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88955 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Health\n",
            "Health\n",
            "Business/Finance\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89089 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software and Development\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Finance/Business\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88944 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics\n",
            "Health\n",
            "Health\n",
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Politics/International Affairs\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89271 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Business/Economy\n",
            "Business/Economy\n",
            "Sports (incorrect categor\n",
            "Toons\n",
            "Sports\n",
            "Business/Finance\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89703 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports (incorrect categorization)\n",
            "None of the given\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89329 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports (assuming it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89220 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Finance/Economy\n",
            "Health\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89754 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89027 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "I'm sorry,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89051 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toons\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Music Feed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88924 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89562 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather/Natural Disasters\n",
            "Employment and Labor\n",
            "Music Feed\n",
            "Politics/Elections\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89187 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89580 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89154 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Politics/Economics\n",
            "Business/Economy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89722 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "None of the above. This article does not fit into any of the given categories.\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89049 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legal/Finance\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics/Current Events\n",
            "Politics/Law\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89291 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88988 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry,\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Software and Development\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88966 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports (incorrect category\n",
            "Sports\n",
            "Business/Finance\n",
            "Business/Trade\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89110 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89068 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Finance/Economy\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89116 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89050 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89277 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89148 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89127 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather/Natural Dis\n",
            "Sci/Tech (This article does not fit into any of the given categories. It is a news article about a political and security issue.)\n",
            "Music Feed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a3dda77d519451c876f3629ba247c14 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89544 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89166 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Economy\n",
            "None of the above\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88968 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Politics/Law\n",
            "Politics\n",
            "Business/Finance\n",
            "Politics/Current Events\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89668 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89464 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89526 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89101 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech (\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Business/Economy\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "Business/Economy\n",
            "I'm sorry,\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software and Development\n",
            "Sci/Tech\n",
            "Finance/Economy\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software and Development\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89170 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics/International Affairs\n",
            "Sports\n",
            "Sports\n",
            "Finance/Economy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88900 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "None of the above\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88989 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Entertainment\n",
            "Toons\n",
            "Health\n",
            "Sports\n",
            "Politics\n",
            "Health\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89146 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health (due to\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89050 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89016 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "This news article belongs\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89124 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech (related to the oil industry and market speculation)\n",
            "Business/Finance\n",
            "Sports\n",
            "Sports\n",
            "Politics/International Relations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89192 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Finance/Economy\n",
            "Sports\n",
            "Politics/Current Affairs\n",
            "I'm sorry,\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89464 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Business/Finance\n",
            "I'm sorry,\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89213 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Retail/Business\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Politics/World News\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89419 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech or\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech or\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88936 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Music Feed\n",
            "Sports\n",
            "Politics or Military Affairs\n",
            "Finance/Investment\n",
            "Health\n",
            "Entertainment\n",
            "Sports\n",
            "Politics/Human Rights\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88877 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics\n",
            "Sports\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Software and Development\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89883 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech\n",
            "I'm sorry,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89095 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89102 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health (due to\n",
            "Business/Finance\n",
            "Entertainment\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89169 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89156 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sports\n",
            "Health\n",
            "Politics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89221 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Sci/Tech or\n",
            "Finance/Economics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89402 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Toons\n",
            "Economy/Politics\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Finance/Economy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89365 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "None of the given\n",
            "Health\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech (\n",
            "None of the above\n",
            "Sci/Tech\n",
            "Health\n",
            "Business/Finance\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Health\n",
            "Health (due to the focus on the number of civilian deaths as a consequence of war)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89222 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "None of the above. This article does not fit into any of the given categories.\n",
            "Software and Development\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89586 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89185 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89089 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89629 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89478 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89036 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Health\n",
            "Health\n",
            "Health\n",
            "None of the given\n",
            "Entertainment\n",
            "This news article belongs to the category of \"Current Events\" or \"Politics\" as it reports on the deployment of the army in response to violent protests during a funeral in Pakistan. It does not fit into any of the given categories.\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89015 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89167 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Business/Finance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89118 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89898 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Software and Development\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89103 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business/Finance\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89397 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics/International Relations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88971 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89090 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88980 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics/Current Affairs\n",
            "Finance/Economy\n",
            "Sci/Tech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88965 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n",
            "Sports\n",
            "I'm sorry, but you have not provided an article for me to categorize. Please provide an article for me to categorize.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-wxLZSKusCTQYH12YWvqkF20t on tokens per min. Limit: 90000 / min. Current: 88932 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retail/Business\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech or Music Feed\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a5aa451145bc91974078c2e7fa859b43 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Health\n",
            "Total Tokens: 113655\n",
            "Prompt Tokens: 111599\n",
            "Completion Tokens: 2056\n",
            "Total Cost (USD): $0.2273100000000002\n",
            "['Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Economy/Finance', 'Sports', 'Politics/Current Events', 'Sports', 'Health', 'Entertainment', 'Business/Finance', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Business/Finance', 'Entertainment', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports (possibly political', 'Sports', 'Politics/Current Events', 'Politics/Current Events', 'Entertainment', 'Sports', 'Sports', 'Business/Finance', 'Politics/Economics', 'Crime/Justice', 'Music Feed', 'Politics', 'Sports', 'Sports', 'Health', 'Health', 'Health', 'Software and Development', 'Music Feed', 'Business/Finance', 'Sci/Tech', 'Finance/Economy', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Employment and Labor', 'Sci/Tech', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Business/Finance', 'This news article belongs', 'Health', 'Health', 'Sports', 'Sci/Tech', 'Software and Development', 'Entertainment', 'Politics/Law', 'Health', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Sports', 'Health', 'Sci/Tech', 'Health', 'Entertainment', 'Health', 'Sports', 'Politics/Current Events', 'Sports', 'Health', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Entertainment', 'Health', 'Software and Development', 'Sports', 'Trade/Economy', 'Sports', 'Politics/Government', 'Sports (incorrect categor', 'Sports', 'Sports', 'Politics/Elections', 'Sports', 'Sci/Tech', 'Entertainment', 'Economics/Finance', 'Sports', 'Sports', 'Sports', 'None of the above', 'Health', 'Animals and Wildlife', 'Entertainment', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Weather/Natural Dis', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Politics/International Relations', 'Entertainment', 'Sports', 'Sci/Tech', 'Politics', 'Sci/Tech', 'Business/Finance', 'Business/Finance', 'Software and Development', 'Sports', 'Politics/Law', 'Software and Development', 'Business/Economy', 'Business/Finance', 'Sci/Tech', 'Health', 'Business/Economy', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Politics', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Entertainment', 'Business/Economy', 'Sports', 'Sports', 'Business/Finance', 'Music Feed', 'Obituary/', 'Sports', 'Sports', 'Health', 'Entertainment', 'None of the given', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Health', 'Politics or World News', 'Sports', 'Sports', 'Toons', 'Sports', 'Entertainment', 'Entertainment', 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Health', 'Sports', 'Software and Development', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Sports', 'Entertainment', 'Sports', 'Entertainment', 'Entertainment', 'Sci/Tech', 'Health', 'Sci/Tech', 'Entertainment', 'Health', 'Sports', 'Sports (This article', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Business/Finance', 'Politics/Current Events', 'Health', 'Health', 'Sports', 'Politics', 'Entertainment', 'Health', 'Sports', 'Music Feed', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Sports', 'Sports', \"I'm sorry,\", 'Sci/Tech', 'Health', 'Sports', 'Music Feed', 'Sports (This is', 'Sci/Tech or', 'Music Feed', 'Entertainment', 'Finance/Economy', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Entertainment', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'Politics', 'Software and Development', 'Entertainment', 'Retail/Sales', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sports', 'Toons', 'Sports', 'Health', 'Health', 'Sports', 'Finance/Business', 'Health (due to', 'Sports', 'Sci/Tech', 'None of the above', 'Business/Finance', 'Sci/Tech', 'Business/Finance', 'Sci/Tech', 'Sci/Tech', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sports', 'Entertainment', 'Politics/International Affairs', 'Business/Economy', 'Entertainment', 'Business/Finance', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sci/Tech', 'Sports', 'Entertainment', 'Weather/Natural Disaster', 'Entertainment', 'Health', 'Sports', 'Sports', 'Business/Economy', 'Sports', 'Health', 'Entertainment', 'Sci/Tech', 'Sports', 'None of the above', 'Health', 'Health (due to', 'Business/Finance', 'Sports', 'Music Feed', 'Health', 'Finance/Business', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Business/Finance', 'Entertainment', 'Toons', 'Sports', 'Economy/Finance', 'Sci/Tech', 'Business/Economy', 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Health', 'Sports', 'Health', 'Sports', 'Sci/Tech', 'Business/Finance', 'Health', 'None of the above', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Entertainment', 'Economics/Business', 'Sports', 'Business/Economy', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sports', 'Entertainment', 'Health', 'Sci/Tech', 'Health', 'Sports', 'Finance/Business', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sports', 'Business/Finance', 'Sports', 'Politics', 'Politics/World News', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Politics', 'Health', 'Entertainment', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sports', 'Sci/Tech', 'Health', 'Sci/Tech', 'Politics', 'Sports', 'Sci/Tech', 'Entertainment', 'Politics/Law', 'Music Feed', 'Sci/Tech (', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sports', 'Politics/International Affairs', 'Sports', 'Sports', 'Business/Finance', 'Sports', 'Entertainment', 'Politics', \"I'm sorry,\", 'Health', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'It is difficult to', 'Politics/International Affairs', 'Sports', 'Sports', 'Sports', 'Finance/Investment', 'Sci/Tech', 'Sports', 'Health', 'Economics/Business', 'Finance/Economy', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Toons', 'Labor/Employment', 'Sports', 'Entertainment', 'Entertainment', 'Entertainment', 'Business/Finance', 'Politics', 'Sports', 'Entertainment', 'None of the above', 'Health', 'Science/Technology (', 'Politics/LGBTQ', 'Sports', 'Sports', 'Sci/Tech', 'Politics', 'Sci/Tech', 'Health (as it', 'Sports', 'Entertainment', 'Sports', 'Politics/International Affairs', 'Sports', 'Politics', 'Sci/Tech', 'This news article falls', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Finance/Economy', 'Sports', 'Health', 'Sports', 'Sports', 'Health', 'Sports (incorrect category', 'Health (as the', 'Sci/Tech', 'Music Feed', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports (This is', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Charity/Fundra', 'Sports', 'Health', 'Sports', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech (', 'Business/Finance', 'Sci/Tech', 'Business/Economics', 'Sci/Tech', 'Natural Disasters/', 'Entertainment', 'Sci/Tech', 'Finance/Business', 'Sci/Tech', 'Politics/International Affairs', 'Sports (as it', 'Politics', 'Retail/Sales', 'Health', 'Sports', 'Sports', 'Sports', 'Entertainment', 'Health', 'Economics/Business', 'Politics/Economics', 'Sci/Tech', 'Health', 'Health', 'Politics/Elections', 'Sports', 'Sports', 'Sports', 'Sports', 'Business/Finance', 'Business/Finance', 'Sports', 'Sci/Tech or', 'Sports', 'Sports', 'Sci/Tech', 'Politics/Current Events', 'Sports', 'Sci/Tech', 'Politics/Economics', 'Business/Finance', 'Sports', 'Sports', 'Business/Economy', 'Sci/Tech', 'Finance/Economy', 'Entertainment', 'Sci/Tech', \"I'm sorry,\", 'Finance/Business', 'Sci/Tech', 'Sports', 'Sports (as the', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Finance/Economy', 'Sports', 'Sports', 'Health', 'Sports', 'Sports', 'None of the given', 'Sci/Tech', 'Sports', 'Politics/Elections', 'Travel/Tourism', 'Business/Finance', 'Sports', 'Politics', 'Sci/Tech', 'Politics', 'Sports', 'Finance/Economics', 'Politics/International Affairs', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Sci/Tech', 'Sports', 'Health', 'Sports', 'Sci/Tech', 'Health (as it', 'Finance/Business', 'Sci/Tech', 'Security/Politics', 'Sci/Tech', 'Entertainment', 'Business/Finance', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Finance/Economy', 'Health', 'Politics/Current Events', 'Health', 'Health', 'Sports (incorrect categor', 'Health', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Politics/Economics', 'Health', 'Sci/Tech', 'Health', 'Sci/Tech', 'Politics/Elections', 'Sports', 'Business/Finance', 'Business/Economics', 'Sci/Tech', 'Entertainment', 'Sports', 'Sports', 'Politics/World News', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Health', 'Sports', 'Entertainment', 'Entertainment', 'Sports', 'Entertainment', 'Sci/Tech', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Politics/Government', 'Sports', 'Politics/Diplom', 'Sports', 'Energy/Commod', 'Health', 'Health', 'Sports', 'Sports', 'Finance/Economy', 'Sports', 'Entertainment', 'Health', 'Sci/Tech', 'Music Feed', 'Crime/Local News', 'Science/Technology', 'Politics', 'Sports', 'Business/Finance', 'Business/Finance', 'Politics/International Affairs', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Health', 'Sci/Tech (', 'Sports', 'Entertainment', 'Sci/Tech', 'Sports', 'Entertainment', 'Entertainment', 'Health', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'None of the above', 'Sports', 'Health', 'Health', 'Business/Finance', 'Software and Development', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Health', 'Sports', 'Sports', 'Finance/Business', 'Politics', 'Health', 'Business/Finance', 'Health', 'Politics/International Affairs', 'Sports', 'Sports', 'Sci/Tech', 'Business/Economy', 'Business/Economy', 'Sports (incorrect categor', 'Toons', 'Sports', 'Health', 'None of the given', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports (assuming it', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Sci/Tech', \"I'm sorry,\", 'Toons', 'Sci/Tech', 'Sports', 'Music Feed', 'Sports', 'Sports', 'Employment and Labor', 'Politics/Elections', 'Sci/Tech', 'Sports', 'Health', 'Health', 'Sports', 'Politics/Economics', 'Health', 'Entertainment', 'Sci/Tech', 'Legal/Finance', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Business/Finance', 'Sci/Tech', \"I'm sorry,\", 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports (incorrect category', 'Sports', 'Business/Finance', 'Sports', 'Sci/Tech', 'Finance/Economy', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Weather/Natural Dis', 'Music Feed', 'Entertainment', 'Business/Economy', 'None of the above', 'Politics/Law', 'Politics', 'Politics/Current Events', 'Sci/Tech', 'Business/Finance', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Entertainment', 'Sports', 'Software and Development', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sci/Tech (', 'Sci/Tech', 'Health', 'Sports', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Business/Economy', \"I'm sorry,\", 'Sports', 'Sports', 'Sports', 'Software and Development', 'Sci/Tech', 'Finance/Economy', 'Sports', 'Sci/Tech', 'Entertainment', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports', 'Politics/International Affairs', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'None of the above', 'Sports', 'Entertainment', 'Sci/Tech', 'Health', 'Entertainment', 'Health', 'Toons', 'Sports', 'Politics', 'Finance/Economy', 'Sci/Tech', 'Health', 'Health (due to', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Health', 'Sci/Tech', 'This news article belongs', 'Sci/Tech', 'Business/Finance', 'Health', 'Sci/Tech', 'Health', 'Business/Finance', 'Health', 'Sports', 'Politics/International Relations', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Finance/Economy', 'Sci/Tech', 'Politics/Current Affairs', \"I'm sorry,\", 'Business/Finance', 'Sports', \"I'm sorry,\", 'Sports', 'Health', 'Retail/Business', 'Sports', 'Sports', 'Sports', 'Sci/Tech or', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech or', 'Music Feed', 'Sports', 'Finance/Investment', 'Politics or Military Affairs', 'Health', 'Entertainment', 'Politics/Human Rights', 'Sci/Tech', 'Sports', 'Politics', 'Sports', 'Music Feed', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Entertainment', 'Software and Development', 'Entertainment', 'Health', 'Sports', 'Health', \"I'm sorry,\", 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Sci/Tech', 'Health (due to', 'Business/Finance', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Business/Finance', 'Sports', 'Business/Finance', 'Sports', 'Politics', 'Sports', 'Health', 'Sci/Tech or', 'Finance/Economics', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Health', 'Sports', 'Sports', 'Entertainment', 'Sci/Tech', 'Economy/Politics', 'Sci/Tech', 'Entertainment', 'Entertainment', 'Sports', 'Sci/Tech', 'Finance/Economy', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Business/Finance', 'Entertainment', 'Sports', 'Sci/Tech', 'Sci/Tech', 'None of the given', 'Health', 'Business/Finance', 'Sports', 'Sci/Tech (', 'None of the above', 'Sci/Tech', 'Health', 'Sports', 'Business/Finance', 'Sci/Tech', 'Business/Finance', 'Health', 'Sports', 'Software and Development', 'Sports', 'Sports', 'Health', 'Health', 'Health', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Health', 'Sports', 'Health', 'Sci/Tech', 'Health', 'Sci/Tech', 'Health', 'Health', 'Health', 'None of the given', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Entertainment', 'Sci/Tech', 'Software and Development', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech']\n",
            "Accuracy on test set: 0.517\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot classification pipeline with LLMs\n",
        "\n",
        "models_v3 = {}\n",
        "\"\"\"\n",
        "[TO BE IMPLEMENTED]\n",
        "        \n",
        "Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n",
        "above to perform zero-shot classification on the test set.\n",
        "\n",
        "You can add other steps to preproces, post-process your data as you see fit. \n",
        "\n",
        "\"\"\"\n",
        "semaphore = Semaphore(2)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "      ('classifier', LLMClassifier(llm_model=llm, prompt_template=news_article_zero_shot_template, semaphore=semaphore)) \n",
        "    ]\n",
        ")\n",
        "\n",
        "# train\n",
        "pipeline.fit(X_train_i, Y_train_i)\n",
        "# predict\n",
        "Y_pred = pipeline.predict(X_test)\n",
        "# record results\n",
        "models_v3[\"zero-shot\"] = {\n",
        "    'test_predictions': Y_pred,\n",
        "    'accuracy': accuracy_score(Y_true, Y_pred),\n",
        "    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred)])\n",
        "}\n",
        "print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(X_test[:3], Y_true[:3]):\n",
        "  print(x, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctIG_tSJ2k9G",
        "outputId": "d4f1e01b-8123-459c-c3db-7c088fa746ed"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AP - Denny Neagle's contract was terminated by the Colorado Rockies on Monday, three days after the oft-injured pitcher was cited for solicitation. Sports\n",
            "The rush by Wal-Mart and other companies to put radio frequency identification devices in their goods could imperil consumer privacy. Software and Developement\n",
            "AP - Tampa Bay Buccaneers owner Malcolm Glazer increased his stake in Manchester United for the third straight trading day, upping his ownership share Tuesday to 28.11 percent and edging closer still to a possible takeover bid. Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_article_few_shot_template = \"\"\"\n",
        "You are an expert at judging the category of which a news article belongs too. \n",
        "Your job is to categorize the category of a given article into one of three categories: Sci/Tech, Software and Developement, Entertainment, Sports, Health, Toons, and Music Feed.\n",
        "\n",
        "Some example tweets along with the correct sentiment are shown below.\n",
        "\n",
        "Article: AP - Denny Neagle's contract was terminated by the Colorado Rockies on Monday, three days after the oft-injured pitcher was cited for solicitation.\n",
        "News article category: Sports\n",
        "\n",
        "Article: The rush by Wal-Mart and other companies to put radio frequency identification devices in their goods could imperil consumer privacy.\n",
        "News article category: Software and Developement\n",
        "\n",
        "Article: AP - Tampa Bay Buccaneers owner Malcolm Glazer increased his stake in Manchester United for the third straight trading day, upping his ownership share Tuesday to 28.11 percent and edging closer still to a possible takeover bid.\n",
        "News article category: Sports\n",
        "\n",
        "Now I want you to label the following example: \n",
        "\n",
        "Article: {article}\n",
        "News article category:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ngzmdf172NIV"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCbruqf6ASV",
        "outputId": "9a00ef90-29b8-4cc0-d3f1-792a3dc56ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Software and Development\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Business\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Natural Disasters/\n",
            "Sports\n",
            "Health\n",
            "Politics/Current Events\n",
            "Sports\n",
            "Politics/Current Events\n",
            "Politics/World News\n",
            "Fashion/Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Business\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Crime or Law Enforcement\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Health\n",
            "Software and Developement\n",
            "Business\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Business/Finance\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Business\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Politics\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Software and Development\n",
            "Sports\n",
            "Trade and Commerce\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech (\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Economy/Finance\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Finance/Business\n",
            "Health\n",
            "Animals and Environment\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Weather/Natural Dis\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Entertainment\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sports\n",
            "Software and Development\n",
            "Health\n",
            "Business\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Health\n",
            "Politics\n",
            "Sports\n",
            "Sports\n",
            "Toons\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Software and Development\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Politics\n",
            "Health\n",
            "Health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd911aba621b2c2340335becd4c2f682 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "I'm sorry,\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech (\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Software and Development\n",
            "Sports\n",
            "Retail/Sales (\n",
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health (due to\n",
            "Automotive\n",
            "Sci/Tech\n",
            "Sci/Tech (\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Business\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Politics\n",
            "Business/Economy\n",
            "Entertainment\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Weather/Natural Disaster\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Business\n",
            "Music Feed\n",
            "Health\n",
            "Finance/Business\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Toons\n",
            "Sports\n",
            "Economics/Finance\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Software and Development\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Travel/International Relations\n",
            "Business/Economy\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech (\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Music Feed\n",
            "Economics/Business\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Finance/Business\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Politics\n",
            "Politics\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Politics\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Politics\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Entertainment\n",
            "Politics\n",
            "I'm sorry,\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "It is unclear from\n",
            "Sci/Tech (\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Toons\n",
            "Labor/Employment\n",
            "Economics/Business\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Entertainment\n",
            "Business/Finance\n",
            "Politics\n",
            "Sports\n",
            "Politics\n",
            "Health\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sci/Tech\n",
            "International News\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aab72b490d1ac8d0a5bac83a0c61f289 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Health\n",
            "None of the given\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Health (as the\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech (\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77be9c97ec18ed8313505ffcf6f2bf21 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charity/Fundra\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Natural Disasters/\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sci/Tech\n",
            "Politics\n",
            "Business/Economy\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Economics/Business\n",
            "Politics\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Politics/Government\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics/Economy\n",
            "Business/Finance\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "I'm sorry,\n",
            "Sci/Tech\n",
            "Finance/Economics\n",
            "Sports\n",
            "It is difficult to\n",
            "Sports\n",
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Politics\n",
            "Travel/Tourism\n",
            "Business/Finance\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Politics\n",
            "Finance\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Legal/Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health (as it\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Politics\n",
            "Health\n",
            "Health\n",
            "Health\n",
            "Politics/Military\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "It is difficult to\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Politics/Government\n",
            "Sports\n",
            "Politics\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Music Feed\n",
            "Entertainment\n",
            "Science/Tech\n",
            "Politics\n",
            "Sci/Tech\n",
            "Business\n",
            "Business/Finance\n",
            "Politics\n",
            "Sports\n",
            "Sports\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd57ae56d84a1a4dc4098eff5432887f in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Software and Developement\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Politics\n",
            "Health\n",
            "Business/Finance\n",
            "Health\n",
            "Politics\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Natural Disaster/Weather\n",
            "Toons\n",
            "Sports\n",
            "Health\n",
            "Politics/International Affairs\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech (\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "I'm sorry,\n",
            "It is impossible to\n",
            "Sci/Tech\n",
            "Sports\n",
            "Music Feed\n",
            "Sports\n",
            "Business\n",
            "Health\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Legal/Politics\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Business\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Business\n",
            "It is unclear what\n",
            "I'm sorry,\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 511d01e33349e3daf3ee325f071d6650 in your message.).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sci/Tech\n",
            "Sports\n",
            "Business/Finance\n",
            "Sports\n",
            "Finance/Economy\n",
            "Finance/Economy\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Weather/Natural Dis\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Business\n",
            "Toons\n",
            "Politics\n",
            "Politics\n",
            "Politics\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Travel/Transportation\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Business\n",
            "I'm sorry,\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Politics/World News\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Weather/Natural Dis\n",
            "Entertainment\n",
            "Health\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Toons\n",
            "Toons and Music\n",
            "Politics\n",
            "Sports\n",
            "Finance/Economy\n",
            "Software and Developement\n",
            "Health\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Health\n",
            "Sci/Tech\n",
            "Politics/Current Events\n",
            "Sci/Tech\n",
            "Business/Finance\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Business\n",
            "Health\n",
            "Sports\n",
            "Sports\n",
            "Politics\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Politics\n",
            "I'm sorry,\n",
            "Sports\n",
            "Sci/Tech\n",
            "I'm sorry,\n",
            "Health\n",
            "Sports\n",
            "Retail/ Business\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Natural Disasters/\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Music Feed\n",
            "Finance\n",
            "Sci/Tech\n",
            "Health\n",
            "Entertainment\n",
            "Politics\n",
            "Entertainment\n",
            "Sports\n",
            "Politics\n",
            "Sports\n",
            "Music Feed\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Software and Development\n",
            "Entertainment\n",
            "Health\n",
            "Entertainment\n",
            "Health\n",
            "Politics\n",
            "I'm sorry,\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Health\n",
            "Business\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Social Issues\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Politics\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Health\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Business/Finance\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "None of the given\n",
            "Sports\n",
            "Business\n",
            "Sci/Tech\n",
            "News/Current Events\n",
            "Sci/Tech\n",
            "Health\n",
            "Sports\n",
            "Business\n",
            "Sci/Tech\n",
            "Business\n",
            "Health\n",
            "Sports\n",
            "Software and Development\n",
            "Sports\n",
            "Health\n",
            "Sports\n",
            "Health\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sports\n",
            "Entertainment\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Health\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Health\n",
            "Health\n",
            "Sci/Tech\n",
            "Entertainment\n",
            "Sports\n",
            "Sports\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sports\n",
            "Entertainment\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Software and Development\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Sports\n",
            "Sci/Tech\n",
            "Sci/Tech\n",
            "Total Tokens: 262522\n",
            "Prompt Tokens: 260599\n",
            "Completion Tokens: 1923\n",
            "Total Cost (USD): $0.5250440000000007\n",
            "['Sports', 'Software and Development', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Politics', 'Sports', 'Health', 'Entertainment', 'Business/Finance', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Business', 'Entertainment', 'Health', 'Sci/Tech', 'Sci/Tech', 'Natural Disasters/', 'Sports', 'Health', 'Politics/Current Events', 'Sports', 'Politics/Current Events', 'Politics/World News', 'Fashion/Entertainment', 'Sports', 'Sports', 'Business', 'Sci/Tech', 'Crime or Law Enforcement', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Health', 'Health', 'Health', 'Software and Developement', 'Music Feed', 'Business', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Health', 'Sci/Tech', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Business/Finance', 'Politics', 'Health', 'Health', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Business', 'Health', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Health', 'Sci/Tech', 'Health', 'Entertainment', 'Health', 'Sports', 'Politics', 'Sports', 'Health', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Entertainment', 'Health', 'Software and Development', 'Sports', 'Trade and Commerce', 'Sports', 'Politics', 'Sci/Tech (', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Entertainment', 'Economy/Finance', 'Sports', 'Sports', 'Sports', 'Finance/Business', 'Health', 'Animals and Environment', 'Entertainment', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Weather/Natural Dis', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Politics', 'Entertainment', 'Sports', 'Sci/Tech', 'Politics', 'Sci/Tech', 'Sci/Tech', 'Software and Development', 'Sci/Tech', 'Sports', 'Health', 'Software and Development', 'Sci/Tech', 'Business', 'Sci/Tech', 'Health', 'Sci/Tech', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Politics', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Entertainment', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Health', 'Entertainment', 'Politics', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Health', 'Politics', 'Sports', 'Sports', 'Toons', 'Sports', 'Entertainment', 'Entertainment', 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Health', 'Sports', 'Software and Development', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Sports', 'Music Feed', 'Sports', 'Entertainment', 'Entertainment', 'Sci/Tech', 'Health', 'Sci/Tech', 'Sci/Tech', 'Health', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Politics', 'Health', 'Health', 'Sports', 'Politics', 'Health', 'Health', 'Sports', 'Music Feed', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Sports', 'Sports', \"I'm sorry,\", 'Sci/Tech', 'Health', 'Sports', 'Entertainment', 'Sci/Tech (', 'Sci/Tech', 'Music Feed', 'Entertainment', 'Finance/Economy', 'Sci/Tech', 'Sci/Tech', 'Health', 'Entertainment', 'Sports', 'Entertainment', 'Health', 'Sports', 'Sci/Tech', 'Politics', 'Software and Development', 'Sports', 'Retail/Sales (', 'Sports', 'Music Feed', 'Sports', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Health', 'Health', 'Sports', 'Sci/Tech', 'Health (due to', 'Automotive', 'Sci/Tech', 'Sci/Tech (', 'Sci/Tech', 'Sci/Tech', 'Business', 'Sci/Tech', 'Sci/Tech', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sports', 'Entertainment', 'Politics', 'Business/Economy', 'Entertainment', 'Business', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sci/Tech', 'Sports', 'Entertainment', 'Weather/Natural Disaster', 'Entertainment', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Health', 'Entertainment', 'Sci/Tech', 'Sports', 'Politics', 'Health', 'Health', 'Business', 'Sports', 'Music Feed', 'Health', 'Finance/Business', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Toons', 'Sports', 'Economics/Finance', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Software and Development', 'Entertainment', 'Sports', 'Health', 'Sports', 'Health', 'Travel/International Relations', 'Business/Economy', 'Sci/Tech', 'Health', 'Sci/Tech (', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Music Feed', 'Economics/Business', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Sports', 'Health', 'Health', 'Sports', 'Entertainment', 'Health', 'Sci/Tech', 'Health', 'Sports', 'Finance/Business', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sports', 'Business/Finance', 'Sports', 'Politics', 'Politics', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Politics', 'Health', 'Entertainment', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sports', 'Sci/Tech', 'Health', 'Sci/Tech', 'Politics', 'Sports', 'Sci/Tech', 'Entertainment', 'Politics', 'Music Feed', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Business', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Business', 'Sports', 'Entertainment', 'Politics', \"I'm sorry,\", 'Health', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'It is unclear from', 'Sci/Tech (', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Health', 'Economics/Business', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Toons', 'Labor/Employment', 'Sports', 'Entertainment', 'Entertainment', 'Entertainment', 'Business/Finance', 'Politics', 'Sports', 'Entertainment', 'Politics', 'Health', 'Sci/Tech', 'Politics', 'Sports', 'Sports', 'Sci/Tech', 'Politics', 'Sci/Tech', 'International News', 'Sports', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Politics', 'Sci/Tech', 'Health', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Business/Finance', 'Sports', 'Health', 'None of the given', 'Sports', 'Health', 'Sci/Tech', 'Health (as the', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech (', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Charity/Fundra', 'Sports', 'Health', 'Sports', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Business/Finance', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Natural Disasters/', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Politics', 'Sci/Tech', 'Politics', 'Business/Economy', 'Health', 'Sports', 'Sci/Tech', 'Sports', 'Entertainment', 'Health', 'Economics/Business', 'Politics', 'Sci/Tech', 'Health', 'Health', 'Politics/Government', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Business', 'Business', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Politics', 'Sports', 'Sci/Tech', 'Politics/Economy', 'Business/Finance', 'Sports', 'Sports', 'Sci/Tech', 'Health', 'Sci/Tech', 'Entertainment', 'Sci/Tech', \"I'm sorry,\", 'Finance/Economics', 'Sci/Tech', 'Sports', 'It is difficult to', 'Sports', 'Sports', 'Music Feed', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Health', 'Sports', 'Sports', 'Health', 'Sci/Tech', 'Sports', 'Politics', 'Travel/Tourism', 'Business/Finance', 'Sports', 'Politics', 'Sci/Tech', 'Politics', 'Sports', 'Finance', 'Politics', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Sci/Tech', 'Sports', 'Health', 'Sports', 'Sci/Tech', 'Legal/Politics', 'Sci/Tech', 'Sci/Tech', 'Health (as it', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Health', 'Politics', 'Health', 'Health', 'Politics/Military', 'Health', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Politics', 'Health', 'Sci/Tech', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'It is difficult to', 'Entertainment', 'Sports', 'Sports', 'Politics', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Health', 'Sports', 'Entertainment', 'Entertainment', 'Sports', 'Entertainment', 'Sci/Tech', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Politics/Government', 'Sports', 'Politics', 'Sports', 'Sci/Tech', 'Health', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Entertainment', 'Health', 'Sci/Tech', 'Music Feed', 'Entertainment', 'Science/Tech', 'Politics', 'Sci/Tech', 'Business', 'Business/Finance', 'Politics', 'Sports', 'Sports', 'Software and Development', 'Sci/Tech', 'Sports', 'Sports', 'Health', 'Sci/Tech', 'Sports', 'Entertainment', 'Sci/Tech', 'Sports', 'Entertainment', 'Entertainment', 'Health', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Health', 'Health', 'Sci/Tech', 'Software and Developement', 'Health', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Health', 'Sports', 'Sports', 'Finance/Economy', 'Politics', 'Health', 'Business/Finance', 'Health', 'Politics', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Natural Disaster/Weather', 'Toons', 'Sports', 'Health', 'Politics/International Affairs', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech (', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Health', 'Sci/Tech', \"I'm sorry,\", 'It is impossible to', 'Sci/Tech', 'Sports', 'Music Feed', 'Sports', 'Business', 'Health', 'Politics', 'Sci/Tech', 'Sports', 'Health', 'Health', 'Sports', 'Sci/Tech', 'Health', 'Entertainment', 'Sci/Tech', 'Legal/Politics', 'Entertainment', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Business', 'Sports', 'Sports', 'Sports', 'Business', 'It is unclear what', \"I'm sorry,\", 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sports', 'Sci/Tech', 'Finance/Economy', 'Health', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Weather/Natural Dis', 'Sci/Tech', 'Entertainment', 'Business', 'Toons', 'Politics', 'Politics', 'Politics', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Entertainment', 'Sports', 'Software and Development', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Travel/Transportation', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Health', 'Sports', 'Sci/Tech', 'Sports', 'Business/Finance', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Business', \"I'm sorry,\", 'Sports', 'Sports', 'Sports', 'Software and Development', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Entertainment', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Sports', 'Sports', 'Politics/World News', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Weather/Natural Dis', 'Entertainment', 'Health', 'Sports', 'Entertainment', 'Sci/Tech', 'Health', 'Toons and Music', 'Health', 'Toons', 'Sports', 'Politics', 'Finance/Economy', 'Software and Developement', 'Health', 'Health', 'Sports', 'Sports', 'Entertainment', 'Sports', 'Health', 'Sci/Tech', 'Politics/Current Events', 'Sci/Tech', 'Business/Finance', 'Health', 'Sci/Tech', 'Health', 'Business', 'Health', 'Sports', 'Politics', 'Sports', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Politics', \"I'm sorry,\", 'Sci/Tech', 'Sports', \"I'm sorry,\", 'Sports', 'Health', 'Retail/ Business', 'Sports', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Sports', 'Natural Disasters/', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Music Feed', 'Sports', 'Finance', 'Sci/Tech', 'Health', 'Entertainment', 'Politics', 'Entertainment', 'Sports', 'Politics', 'Sports', 'Music Feed', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Entertainment', 'Software and Development', 'Entertainment', 'Health', 'Politics', 'Health', \"I'm sorry,\", 'Sports', 'Sci/Tech', 'Entertainment', 'Sports', 'Sci/Tech', 'Health', 'Business', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Social Issues', 'Sci/Tech', 'Sports', 'Politics', 'Sports', 'Health', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Health', 'Sports', 'Entertainment', 'Health', 'Sports', 'Sports', 'Entertainment', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Entertainment', 'Sci/Tech', 'Business/Finance', 'Entertainment', 'Sports', 'Sci/Tech', 'Sci/Tech', 'None of the given', 'Health', 'Business', 'Sports', 'Sci/Tech', 'News/Current Events', 'Sci/Tech', 'Health', 'Sports', 'Business', 'Sci/Tech', 'Business', 'Health', 'Sports', 'Software and Development', 'Sports', 'Sports', 'Health', 'Health', 'Health', 'Health', 'Sci/Tech', 'Sports', 'Sports', 'Entertainment', 'Health', 'Sci/Tech', 'Health', 'Sci/Tech', 'Health', 'Sci/Tech', 'Sci/Tech', 'Health', 'Health', 'Sci/Tech', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'Sports', 'Entertainment', 'Sports', 'Sports', 'Sci/Tech', 'Sci/Tech', 'Software and Development', 'Sci/Tech', 'Sci/Tech', 'Sci/Tech', 'Sports', 'Sci/Tech', 'Sci/Tech']\n",
            "Accuracy on test set: 0.534\n"
          ]
        }
      ],
      "source": [
        "# Few-shot classification with LLMs\n",
        "\n",
        "\"\"\"\n",
        "[TO BE IMPLEMENTED]\n",
        "        \n",
        "Goal: initialized below is a dummy sklearn Pipeline object with no steps.\n",
        "You have to replace it with a pipeline object which uses the `LLMClassifier` you have implemented \n",
        "above to perform few-shot classification on the test set.\n",
        "\n",
        "With few-shot classification, you can pass upto 5 demonstration examples as part of the prompt \n",
        "to the LLM. You can add other steps to preproces, post-process your data as you see fit. \n",
        "\n",
        "\"\"\"\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "      ('classifier', LLMClassifier(llm_model=llm, prompt_template=news_article_few_shot_template, semaphore=semaphore)) \n",
        "    ]\n",
        ")\n",
        "\n",
        "# train\n",
        "pipeline.fit(X_train_i, Y_train_i)\n",
        "# predict\n",
        "Y_pred_i = pipeline.predict(X_test)\n",
        "# record results\n",
        "models_v3[\"few-shot\"] = {\n",
        "    'test_predictions': Y_pred_i,\n",
        "    'accuracy': accuracy_score(Y_true, Y_pred_i),\n",
        "    'f1': f1_score(Y_true, Y_pred_i, average='weighted'),\n",
        "    'errors': sum([x != y for (x, y) in zip(Y_true, Y_pred_i)])\n",
        "}\n",
        "print(\"Accuracy on test set: {}\".format(accuracy_score(Y_true, Y_pred_i)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdQDQ8Sla2u3"
      },
      "source": [
        "## Step 5: Report Results from previous two steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "IpKaurcHa0Vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7771a91-9a60-4f87-d618-05e01e3a18f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram Models: \n",
            "Train size: 500  |  Accuracy: 0.303  |  F1 score: 0.16343520671051212 |  Num errors: 697\n",
            "Train size: 1000  |  Accuracy: 0.216  |  F1 score: 0.10880678256758546 |  Num errors: 784\n",
            "Train size: 2000  |  Accuracy: 0.329  |  F1 score: 0.21644958343160567 |  Num errors: 671\n",
            "Train size: 5000  |  Accuracy: 0.352  |  F1 score: 0.26360265195289206 |  Num errors: 648\n",
            "Train size: 10000  |  Accuracy: 0.281  |  F1 score: 0.2310255973993498 |  Num errors: 719\n",
            "Train size: 25000  |  Accuracy: 0.368  |  F1 score: 0.3551272825603496 |  Num errors: 632\n"
          ]
        }
      ],
      "source": [
        "# Report results\n",
        "\n",
        "print(\"N-gram Models: \")\n",
        "for train_size, result in models.items():\n",
        "    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n",
        "        train_size,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "Rztr78oD6EQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c690f905-3f6d-44d4-9d20-9686e3026933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained Transformer Models: \n",
            "Train size: 500  |  Accuracy: 0.717  |  F1 score: 0.7083022505473252 |  Num errors: 283\n",
            "Train size: 1000  |  Accuracy: 0.74  |  F1 score: 0.7321001798864292 |  Num errors: 260\n",
            "Train size: 2000  |  Accuracy: 0.75  |  F1 score: 0.7413502143733617 |  Num errors: 250\n",
            "Train size: 5000  |  Accuracy: 0.767  |  F1 score: 0.7599778036819289 |  Num errors: 233\n",
            "Train size: 10000  |  Accuracy: 0.771  |  F1 score: 0.7635818154780631 |  Num errors: 229\n",
            "Train size: 25000  |  Accuracy: 0.789  |  F1 score: 0.7812156072716253 |  Num errors: 211\n"
          ]
        }
      ],
      "source": [
        "print(\"Pretrained Transformer Models: \")\n",
        "for train_size, result in models_v2.items():\n",
        "    print(\"Train size: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n",
        "        train_size,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "b_sQOJW36Cqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8944ac46-3973-4c5a-e003-18c64bb52fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Language Models: \n",
            "Mode: zero-shot  |  Accuracy: 0.517  |  F1 score: 0.7812156072716253 |  Num errors: 483\n",
            "Mode: few-shot  |  Accuracy: 0.534  |  F1 score: 0.5193196290625451 |  Num errors: 466\n"
          ]
        }
      ],
      "source": [
        "print(\"Large Language Models: \")\n",
        "for mode, result in models_v3.items():\n",
        "    print(\"Mode: {0}  |  Accuracy: {1}  |  F1 score: {2} |  Num errors: {3}\".format(\n",
        "        mode,\n",
        "        result['accuracy'],\n",
        "        result['f1'],\n",
        "        result['errors']\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v882hLIa6gR"
      },
      "source": [
        "## Step 6: Data Augmentation [Optional]\n",
        "\n",
        "In this section, we want to explore how to augment data efficiently to your existing training data. This is a very empirical exercise with a less well-defined playbook which means this section of the project is going to be open ended. Let us first understand what we mean by efficiency here, and why it matters:\n",
        "\n",
        "### Performance Gain (G):\n",
        "We will measure performance gain from data augmentation as the improvement in model accuracy (reduction in num. errors) on the Test dataset as defined above. \n",
        "\n",
        "### Budget (K):\n",
        "We will measure \"budget\" as the number of additional rows augmentated to the original training dataset.  In this project, the universe of data from which you will select to add to your training set is Datasets['augment'] (and downstream X_augment, Y_augment).\n",
        "\n",
        "This data is already labeled of course, but in most real-world scenarios the additional data is typically unlabeled. In order to augment it to your training data, you have to get it annotated which incurs some cost in time & money. This is the motivation to consider budget as a metric.\n",
        "\n",
        "### Efficiency (E = G / K): \n",
        "Efficiency = Performance Gain (Reduction in num errors in test set) / Budget (Number of additional rows augmented to the training dataset)\n",
        "\n",
        "We want to get the maximum gain in performance, while incurring minimum annotation cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a-kk3Pk6Jx-"
      },
      "source": [
        "\n",
        "\n",
        "We can always sample more data at random from the augmentation set, and this is probably the first thing to try. Can we be more intelligent with the data we choose to augment to the training dataset?\n",
        "\n",
        "**Idea 1**: Look at the test errors that the current model is making. How can this help us guide our \"data collection\" for augmentation? One possible idea is to select examples from the augmentation dataset that are similar to these errors and add them to the training data. Similarity can be approximated in many ways:\n",
        "1. [Jaccard distance between two texts](https://studymachinelearning.com/jaccard-similarity-text-similarity-metric-in-nlp/)\n",
        "2. L2 distance between mean word vectors (we already compute these features for the entire dataset using WordVectorFeaturizer)\n",
        "3. L2 distance between sentence transformer embedding (we already compute these features for the entire dataset using TransformerFeaturizer)\n",
        "  \n",
        "\n",
        "**Idea 2**: Compute model's predictions on the augmentation dataset, and include those examples to the training dataset that the model finds \"hard\" ? (a proxy for this would be to look at cases where the output score distribution across all labels has nearly identical scores for top two or three labels).\n",
        "\n",
        "**Idea 3**: Look at the test errors that the current model is making, and the distribution of these errors across labels. Select examples from the augmentation dataset that belong to these classes - adding more training data for labels that the curent model does not do well on, can improve performance (assuming label quality is good)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UVN6r0abKHI"
      },
      "outputs": [],
      "source": [
        "# Examine current test errors\n",
        "test_errors = []\n",
        "Y_pred_i = models[25000]['test_predictions']\n",
        "\n",
        "for idx, label in enumerate(Y_true):\n",
        "    if label != Y_pred_i[idx]:\n",
        "        test_errors.append((X_test[idx], label,  Y_pred_i[idx]))\n",
        "\n",
        "print(\"Number of errors in the test set: {}\".format(len(test_errors)))\n",
        "print(\"Example errors: [example, true label, predicted label]\")\n",
        "for i in range(10):\n",
        "    print(test_errors[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2LCwb4ibYsV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "[TO BE IMPLEMENTED]\n",
        "\n",
        "Your additional data augmentation explorations go here\n",
        "\n",
        "For instance, the pseudocode for Idea (1) might look like the following:\n",
        "\n",
        "Augmented = {}\n",
        "For e in test_errors:\n",
        "   1. X_nn, y_nn = k nearest neighbors to (e) from X_augment, y_augment\n",
        "   2. Add each (x, y) from (X_nn, y_nn) to Augmented\n",
        "\n",
        "Add the Augmented examples to the training set\n",
        "Train the new model and record performance improvements\n",
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce6b242414a543c2a12ed96d0b172e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91317d2d089f4dfe853c38cd730b7fab",
              "IPY_MODEL_27d32f550564433eaba12c93169857fc",
              "IPY_MODEL_9a7279d57acf492584ecf083bb29e343"
            ],
            "layout": "IPY_MODEL_aa962c230f9442168ff130d8c24965df"
          }
        },
        "91317d2d089f4dfe853c38cd730b7fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ede7440670e84051898ad7de850dc51a",
            "placeholder": "​",
            "style": "IPY_MODEL_2a8eb5097af34051b00b1b73a1ebabda",
            "value": "Downloading (…)a8e1d/.gitattributes: 100%"
          }
        },
        "27d32f550564433eaba12c93169857fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b31dfb9710470d925bc5a4d28749f3",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fe92088226c4e7d85fd6ec9d0ca328b",
            "value": 1175
          }
        },
        "9a7279d57acf492584ecf083bb29e343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca04b44470745a3b257c36a5c128f25",
            "placeholder": "​",
            "style": "IPY_MODEL_94514a4f0735411d8c0c315d082dab8c",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 64.2kB/s]"
          }
        },
        "aa962c230f9442168ff130d8c24965df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede7440670e84051898ad7de850dc51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8eb5097af34051b00b1b73a1ebabda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b31dfb9710470d925bc5a4d28749f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe92088226c4e7d85fd6ec9d0ca328b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca04b44470745a3b257c36a5c128f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94514a4f0735411d8c0c315d082dab8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d90731d190b146b29cf1cc0ce7371f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a412a0902f44c47a5722077b1ae3cea",
              "IPY_MODEL_47f5e52078d4420db01dc8cb7cafae8a",
              "IPY_MODEL_258b6ddc2b9a49988586f8ee285fd582"
            ],
            "layout": "IPY_MODEL_2f0d937f49b74557ab62a59696678273"
          }
        },
        "4a412a0902f44c47a5722077b1ae3cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a3d9df550e476f8e7b8126a1754023",
            "placeholder": "​",
            "style": "IPY_MODEL_1a16643528c0498d87bd99cb439d0f3d",
            "value": "Downloading (…)_Pooling/config.json: 100%"
          }
        },
        "47f5e52078d4420db01dc8cb7cafae8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb14e86eda594f498ecfa3ac4426a829",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcbf588918514566852ba12725188f3e",
            "value": 190
          }
        },
        "258b6ddc2b9a49988586f8ee285fd582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34aa730a9f9f480390d84fe8cb314423",
            "placeholder": "​",
            "style": "IPY_MODEL_af41c783e07643218341143e44b34945",
            "value": " 190/190 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "2f0d937f49b74557ab62a59696678273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a3d9df550e476f8e7b8126a1754023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a16643528c0498d87bd99cb439d0f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb14e86eda594f498ecfa3ac4426a829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbf588918514566852ba12725188f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34aa730a9f9f480390d84fe8cb314423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af41c783e07643218341143e44b34945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8c4b5d46b534647b56e28be51c71143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f85fdbc2948c40b8922da88e56048018",
              "IPY_MODEL_b6702432569e462b80b65652a1bef61d",
              "IPY_MODEL_1a3de692fe6b4334a54177d09f0b1537"
            ],
            "layout": "IPY_MODEL_adcc4450f2774f12a972ae6730d51f2f"
          }
        },
        "f85fdbc2948c40b8922da88e56048018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3beb5860a31413b8e7f98c2ec5d51ab",
            "placeholder": "​",
            "style": "IPY_MODEL_011bf0714df9442db9081a6c0057b489",
            "value": "Downloading (…)b20bca8e1d/README.md: 100%"
          }
        },
        "b6702432569e462b80b65652a1bef61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b344f30766694376b26811f8996e08e3",
            "max": 10571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19e57fbcf2dd45a5b457665422592b37",
            "value": 10571
          }
        },
        "1a3de692fe6b4334a54177d09f0b1537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8260a40e68442ff81d0b447628f6e82",
            "placeholder": "​",
            "style": "IPY_MODEL_7e1ca31766d74fb39e52651b4f912e5d",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 758kB/s]"
          }
        },
        "adcc4450f2774f12a972ae6730d51f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3beb5860a31413b8e7f98c2ec5d51ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011bf0714df9442db9081a6c0057b489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b344f30766694376b26811f8996e08e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e57fbcf2dd45a5b457665422592b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8260a40e68442ff81d0b447628f6e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1ca31766d74fb39e52651b4f912e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a72c1a13a5ad428188e3152be9096148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ed61b77e193438593a8669fb67db110",
              "IPY_MODEL_b2a716de3b434eb8b9a4e1b479347bc7",
              "IPY_MODEL_c20ac4536338433395437677287afff7"
            ],
            "layout": "IPY_MODEL_a560f5f8fe2d4d5e8e742f63f24c8d65"
          }
        },
        "5ed61b77e193438593a8669fb67db110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174bcbf0f3d7426883721f66d8b89dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_458edd02de9d47f8b437707e25599d39",
            "value": "Downloading (…)0bca8e1d/config.json: 100%"
          }
        },
        "b2a716de3b434eb8b9a4e1b479347bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11617e6c55ec41fbb4ce751e7321dc6d",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22be8668de104753996c2def67c461f9",
            "value": 571
          }
        },
        "c20ac4536338433395437677287afff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869a56e33c1b4497a994cdd237ee8182",
            "placeholder": "​",
            "style": "IPY_MODEL_4287e71ffa84420ebd455d6fa8911d6d",
            "value": " 571/571 [00:00&lt;00:00, 37.7kB/s]"
          }
        },
        "a560f5f8fe2d4d5e8e742f63f24c8d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174bcbf0f3d7426883721f66d8b89dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458edd02de9d47f8b437707e25599d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11617e6c55ec41fbb4ce751e7321dc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22be8668de104753996c2def67c461f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "869a56e33c1b4497a994cdd237ee8182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4287e71ffa84420ebd455d6fa8911d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb46db6a67a4ff1a9c76dff39cd96b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f4d0ef082146a9918e39fa17161357",
              "IPY_MODEL_428489140653408fad835d49db6351ea",
              "IPY_MODEL_7103b66eec084c6d99cd860820332555"
            ],
            "layout": "IPY_MODEL_78a7c67427204cab8157bd5ef7f86011"
          }
        },
        "72f4d0ef082146a9918e39fa17161357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33cce55cfdf44bd7bce072e3959eea2e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f9fe7dc8fdb45d3bac2d11f8b83aa15",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "428489140653408fad835d49db6351ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3158a21871e549baac7e2238a4f70c6f",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce8107b5f1744244a71a039f7b722d7d",
            "value": 116
          }
        },
        "7103b66eec084c6d99cd860820332555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079ab707a9644a46a921128f52975e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_744fda458d6f410b96c2a863276dac3c",
            "value": " 116/116 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "78a7c67427204cab8157bd5ef7f86011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33cce55cfdf44bd7bce072e3959eea2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9fe7dc8fdb45d3bac2d11f8b83aa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3158a21871e549baac7e2238a4f70c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8107b5f1744244a71a039f7b722d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "079ab707a9644a46a921128f52975e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744fda458d6f410b96c2a863276dac3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "812e1f6d4aa849e49df5a04e9786720e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ce06b37eb7e4a3981de3aa5711e3e4b",
              "IPY_MODEL_4a36e669e0434b1a8099ee71b3414361",
              "IPY_MODEL_2bffc337134f438c91e49d8b0ed07d30"
            ],
            "layout": "IPY_MODEL_bae40bf6eb74481485c3277004e292c0"
          }
        },
        "5ce06b37eb7e4a3981de3aa5711e3e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24077d10323e4cf6afde6bda07acd730",
            "placeholder": "​",
            "style": "IPY_MODEL_213afabd53af495c8f83ae9f1c26febb",
            "value": "Downloading (…)e1d/data_config.json: 100%"
          }
        },
        "4a36e669e0434b1a8099ee71b3414361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5cee99e3a54d66af6847f47ac6ab55",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99d2c0833c19444e8ab98ef4a2cb11c8",
            "value": 39265
          }
        },
        "2bffc337134f438c91e49d8b0ed07d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5e27627ffd84dd1b63010ad1daabfde",
            "placeholder": "​",
            "style": "IPY_MODEL_76a5311597d042268f7c946308762f9c",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 2.34MB/s]"
          }
        },
        "bae40bf6eb74481485c3277004e292c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24077d10323e4cf6afde6bda07acd730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213afabd53af495c8f83ae9f1c26febb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd5cee99e3a54d66af6847f47ac6ab55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d2c0833c19444e8ab98ef4a2cb11c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5e27627ffd84dd1b63010ad1daabfde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a5311597d042268f7c946308762f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea736852d2b84c17bbc771438f6920ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_626781fb818f45d5832170c5f829ee10",
              "IPY_MODEL_81a84dffaa6c49199ac1abeb3ba62a63",
              "IPY_MODEL_e7cb90886355466085cf66ad8f44e160"
            ],
            "layout": "IPY_MODEL_fe0a6d565f3b403dbb66d775c7e189af"
          }
        },
        "626781fb818f45d5832170c5f829ee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43756d0b116419ba552455db87417df",
            "placeholder": "​",
            "style": "IPY_MODEL_7e78d2258d7346b3ab7595f22ecb8205",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "81a84dffaa6c49199ac1abeb3ba62a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f4b370603c84962913f9b66d8ec2586",
            "max": 438011953,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_488d9a5010a24efeb6985506a0bef4d8",
            "value": 438011953
          }
        },
        "e7cb90886355466085cf66ad8f44e160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ef15b3c55b4200a45e3eead2792354",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3891f787c54f83b820f62404ecabc0",
            "value": " 438M/438M [00:01&lt;00:00, 192MB/s]"
          }
        },
        "fe0a6d565f3b403dbb66d775c7e189af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43756d0b116419ba552455db87417df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e78d2258d7346b3ab7595f22ecb8205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f4b370603c84962913f9b66d8ec2586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "488d9a5010a24efeb6985506a0bef4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ef15b3c55b4200a45e3eead2792354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3891f787c54f83b820f62404ecabc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e2d6d03bb7c40f18c1a46ed99da73c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18e8ea145f89464aac7b163afd2b9dfc",
              "IPY_MODEL_de496407a2bc4fb98eedca6706f5b429",
              "IPY_MODEL_fa591e825d5442aa9639a4568ad02552"
            ],
            "layout": "IPY_MODEL_6db2c06e51f5402b8137039c82af0803"
          }
        },
        "18e8ea145f89464aac7b163afd2b9dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da46b503a7e24d6bae1ff5db3681868d",
            "placeholder": "​",
            "style": "IPY_MODEL_92c3e4225dab40c89182c2611cd71ed7",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "de496407a2bc4fb98eedca6706f5b429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59eb19543b245c4a9cc493ee6772329",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e730b6bcbba942c09256130d68f77f71",
            "value": 53
          }
        },
        "fa591e825d5442aa9639a4568ad02552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401e4c08170f4aa48ce605fa6a3ee1b6",
            "placeholder": "​",
            "style": "IPY_MODEL_978f73bf9b3548b89e57849227ccd8d8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.20kB/s]"
          }
        },
        "6db2c06e51f5402b8137039c82af0803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da46b503a7e24d6bae1ff5db3681868d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c3e4225dab40c89182c2611cd71ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d59eb19543b245c4a9cc493ee6772329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e730b6bcbba942c09256130d68f77f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "401e4c08170f4aa48ce605fa6a3ee1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978f73bf9b3548b89e57849227ccd8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4347ed40174040eb89aad90e43ef1112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688af4afda9e41148ad54e99a8731724",
              "IPY_MODEL_d40b00a3c2704c1f8cb27fc49046e974",
              "IPY_MODEL_e345ba1383a549f9b074399c1042579d"
            ],
            "layout": "IPY_MODEL_fafd37af020147c9905812e86a2b644a"
          }
        },
        "688af4afda9e41148ad54e99a8731724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5db9f2e1624bf19d7d3a7586245423",
            "placeholder": "​",
            "style": "IPY_MODEL_37b2a31550e14436b8420e3424a93999",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "d40b00a3c2704c1f8cb27fc49046e974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745942be41a740a6a911e259f0c9d194",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ce0bdecef1b4ddd9f9f77b0ee1e62d7",
            "value": 239
          }
        },
        "e345ba1383a549f9b074399c1042579d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c53c2bb33944ed89baab45e3c5bea6c",
            "placeholder": "​",
            "style": "IPY_MODEL_97facc0b5dbd4965bb39322f93665a02",
            "value": " 239/239 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "fafd37af020147c9905812e86a2b644a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5db9f2e1624bf19d7d3a7586245423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b2a31550e14436b8420e3424a93999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "745942be41a740a6a911e259f0c9d194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce0bdecef1b4ddd9f9f77b0ee1e62d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c53c2bb33944ed89baab45e3c5bea6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97facc0b5dbd4965bb39322f93665a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb99ed57ebdd458fae1a48106352dd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e9b28fa3c454a7baaa78d2ee523c792",
              "IPY_MODEL_5e1a9e1ebf954a269bcd50f033dfc43c",
              "IPY_MODEL_fd68d0871911447c93358ff464c866b4"
            ],
            "layout": "IPY_MODEL_3baad48d4ced432585a62918d442ca6e"
          }
        },
        "0e9b28fa3c454a7baaa78d2ee523c792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04de71694544085b531e09e6def6f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_7cbbdb94212748e6911ac9d30eba34a0",
            "value": "Downloading (…)a8e1d/tokenizer.json: 100%"
          }
        },
        "5e1a9e1ebf954a269bcd50f033dfc43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f518014fc7a44f790b1b446a247894a",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b30d8ea3fea4a5ab2cc21ce756fc6bd",
            "value": 466021
          }
        },
        "fd68d0871911447c93358ff464c866b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d59bfa446046c9af2c67620135a20a",
            "placeholder": "​",
            "style": "IPY_MODEL_45c5318e9cf842d4817cd8b117ff4e03",
            "value": " 466k/466k [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "3baad48d4ced432585a62918d442ca6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b04de71694544085b531e09e6def6f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbbdb94212748e6911ac9d30eba34a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f518014fc7a44f790b1b446a247894a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b30d8ea3fea4a5ab2cc21ce756fc6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94d59bfa446046c9af2c67620135a20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c5318e9cf842d4817cd8b117ff4e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b267c6bf27ef4d0c8fb7f7fc112368af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5130fcd0504a409699da09d47bf1d537",
              "IPY_MODEL_c065db433d76453b94826e15d245eb2b",
              "IPY_MODEL_8163c2c78cb0437d952ad00574e076a9"
            ],
            "layout": "IPY_MODEL_bef9fdb11d25408cbfeaadb8d01bd69f"
          }
        },
        "5130fcd0504a409699da09d47bf1d537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27eb19b261114aaab0253d9afa0ff439",
            "placeholder": "​",
            "style": "IPY_MODEL_865b0e1763b04ddb81aeff8f918eef24",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c065db433d76453b94826e15d245eb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6572dd645f7f4ef9bad2c1ba83526c79",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_503c8783e9654b3f89b5ec8d5f635619",
            "value": 363
          }
        },
        "8163c2c78cb0437d952ad00574e076a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c277d723381b4bbbb1bb8646501ceb05",
            "placeholder": "​",
            "style": "IPY_MODEL_2dd7f51aa6b4455e8f653c7ff0c40d0e",
            "value": " 363/363 [00:00&lt;00:00, 30.4kB/s]"
          }
        },
        "bef9fdb11d25408cbfeaadb8d01bd69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27eb19b261114aaab0253d9afa0ff439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865b0e1763b04ddb81aeff8f918eef24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6572dd645f7f4ef9bad2c1ba83526c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503c8783e9654b3f89b5ec8d5f635619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c277d723381b4bbbb1bb8646501ceb05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd7f51aa6b4455e8f653c7ff0c40d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c5de0a98f114053be462ef884523a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7502f625c49d48dd8a524ee36a599db6",
              "IPY_MODEL_576e7e389c6d48cebcf0e00784cc8710",
              "IPY_MODEL_a4d594638dd142819603b19ddf1de4f3"
            ],
            "layout": "IPY_MODEL_bc86582d71be47d8982fbf17a6b88f45"
          }
        },
        "7502f625c49d48dd8a524ee36a599db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222fe2ed179f4189b000396d04d09453",
            "placeholder": "​",
            "style": "IPY_MODEL_be9d953a535c4092aa0c0948040b1976",
            "value": "Downloading (…)8e1d/train_script.py: 100%"
          }
        },
        "576e7e389c6d48cebcf0e00784cc8710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed2519972754db6ba02a0e10a9bdee8",
            "max": 13123,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b87f0ec3ee42a8b8d5796851df3dee",
            "value": 13123
          }
        },
        "a4d594638dd142819603b19ddf1de4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b182eccbd659427cb3beebe38c059747",
            "placeholder": "​",
            "style": "IPY_MODEL_bf32f383e1b9434f85c94bb49964ee08",
            "value": " 13.1k/13.1k [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "bc86582d71be47d8982fbf17a6b88f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222fe2ed179f4189b000396d04d09453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9d953a535c4092aa0c0948040b1976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed2519972754db6ba02a0e10a9bdee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b87f0ec3ee42a8b8d5796851df3dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b182eccbd659427cb3beebe38c059747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf32f383e1b9434f85c94bb49964ee08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e19e287e06d4c4d9183fe019601a70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8160e15f48b64f9ea474656adc81f579",
              "IPY_MODEL_796b854a480248c498b22eb79cc3cf79",
              "IPY_MODEL_4fb57ef81d304ad190432e272e4e94bf"
            ],
            "layout": "IPY_MODEL_ce3b3f1c16e74050b212627e1831fb45"
          }
        },
        "8160e15f48b64f9ea474656adc81f579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef5a50ad6644535a5ffea66da7c84f5",
            "placeholder": "​",
            "style": "IPY_MODEL_1bc35ad64b594245b0c07bdba57eb1c6",
            "value": "Downloading (…)b20bca8e1d/vocab.txt: 100%"
          }
        },
        "796b854a480248c498b22eb79cc3cf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73fea98782484662827520c5c2998ec2",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6507ac8b8404e698dbd364256b6baab",
            "value": 231536
          }
        },
        "4fb57ef81d304ad190432e272e4e94bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc4b38d311594dd1b0bdf80e21f17b41",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d1fe4f52d947348942844eddb0c537",
            "value": " 232k/232k [00:00&lt;00:00, 551kB/s]"
          }
        },
        "ce3b3f1c16e74050b212627e1831fb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef5a50ad6644535a5ffea66da7c84f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc35ad64b594245b0c07bdba57eb1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fea98782484662827520c5c2998ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6507ac8b8404e698dbd364256b6baab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc4b38d311594dd1b0bdf80e21f17b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d1fe4f52d947348942844eddb0c537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ad8c39f74e43568140540f37b84e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_463b2fa34dee496a98718b0b1ae8eecc",
              "IPY_MODEL_b8763e22f8594f7a9e43eeb86a502be3",
              "IPY_MODEL_ae57381c7ebe4a4e87d120bddc8693df"
            ],
            "layout": "IPY_MODEL_3c560c77c66343649c063acf259c73e9"
          }
        },
        "463b2fa34dee496a98718b0b1ae8eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c21db243c741839f3d48c712545be8",
            "placeholder": "​",
            "style": "IPY_MODEL_f513ff2903a84881842ac7762ccc4f38",
            "value": "Downloading (…)bca8e1d/modules.json: 100%"
          }
        },
        "b8763e22f8594f7a9e43eeb86a502be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf1a83a2d6348fa9160f2f7cd676813",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28997092dee041688460f0fe077e48de",
            "value": 349
          }
        },
        "ae57381c7ebe4a4e87d120bddc8693df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2e793087c648d08201578a7a4e1f37",
            "placeholder": "​",
            "style": "IPY_MODEL_5a7a2425094e4c1a9f6caf522eb9a64f",
            "value": " 349/349 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "3c560c77c66343649c063acf259c73e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c21db243c741839f3d48c712545be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f513ff2903a84881842ac7762ccc4f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf1a83a2d6348fa9160f2f7cd676813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28997092dee041688460f0fe077e48de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b2e793087c648d08201578a7a4e1f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a7a2425094e4c1a9f6caf522eb9a64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}